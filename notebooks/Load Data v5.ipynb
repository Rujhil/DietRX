{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pickle\n",
    "from sqlalchemy import func\n",
    "from sqlalchemy.inspection import inspect\n",
    "\n",
    "from core import app, db\n",
    "from models import *\n",
    "\n",
    "DATA = Path('./data/version-3/')\n",
    "DBDUMP = Path('data/db-dump/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Foods: 6980\n",
      "Total Diseases: 7610\n",
      "Total Genes: 20558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sneha\\AppData\\Local\\Temp\\ipykernel_9108\\2356757312.py:2: SAWarning: relationship 'Disease.foods' will copy column disease.disease_id to column food_disease.disease_id, which conflicts with relationship(s): 'Food.diseases' (copies disease.disease_id to food_disease.disease_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"diseases\"' to the 'Disease.foods' relationship. (Background on this warning at: https://sqlalche.me/e/20/qzyx) (This warning originated from the `configure_mappers()` process, which was invoked automatically in response to a user-initiated operation.)\n",
      "  print(\"Total Foods:\", db.session.query(Food.food_id).distinct().count())\n",
      "C:\\Users\\Sneha\\AppData\\Local\\Temp\\ipykernel_9108\\2356757312.py:2: SAWarning: relationship 'Disease.foods' will copy column food.food_id to column food_disease.food_id, which conflicts with relationship(s): 'Food.diseases' (copies food.food_id to food_disease.food_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"diseases\"' to the 'Disease.foods' relationship. (Background on this warning at: https://sqlalche.me/e/20/qzyx) (This warning originated from the `configure_mappers()` process, which was invoked automatically in response to a user-initiated operation.)\n",
      "  print(\"Total Foods:\", db.session.query(Food.food_id).distinct().count())\n",
      "C:\\Users\\Sneha\\AppData\\Local\\Temp\\ipykernel_9108\\2356757312.py:2: SAWarning: relationship 'Gene.diseases' will copy column gene.gene_id to column disease_gene.gene_id, which conflicts with relationship(s): 'Disease.genes' (copies gene.gene_id to disease_gene.gene_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"genes\"' to the 'Gene.diseases' relationship. (Background on this warning at: https://sqlalche.me/e/20/qzyx) (This warning originated from the `configure_mappers()` process, which was invoked automatically in response to a user-initiated operation.)\n",
      "  print(\"Total Foods:\", db.session.query(Food.food_id).distinct().count())\n",
      "C:\\Users\\Sneha\\AppData\\Local\\Temp\\ipykernel_9108\\2356757312.py:2: SAWarning: relationship 'Gene.diseases' will copy column disease.disease_id to column disease_gene.disease_id, which conflicts with relationship(s): 'Disease.genes' (copies disease.disease_id to disease_gene.disease_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"genes\"' to the 'Gene.diseases' relationship. (Background on this warning at: https://sqlalche.me/e/20/qzyx) (This warning originated from the `configure_mappers()` process, which was invoked automatically in response to a user-initiated operation.)\n",
      "  print(\"Total Foods:\", db.session.query(Food.food_id).distinct().count())\n",
      "C:\\Users\\Sneha\\AppData\\Local\\Temp\\ipykernel_9108\\2356757312.py:2: SAWarning: relationship 'Gene.foods' will copy column gene.gene_id to column food_gene.gene_id, which conflicts with relationship(s): 'Food.genes' (copies gene.gene_id to food_gene.gene_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"genes\"' to the 'Gene.foods' relationship. (Background on this warning at: https://sqlalche.me/e/20/qzyx) (This warning originated from the `configure_mappers()` process, which was invoked automatically in response to a user-initiated operation.)\n",
      "  print(\"Total Foods:\", db.session.query(Food.food_id).distinct().count())\n",
      "C:\\Users\\Sneha\\AppData\\Local\\Temp\\ipykernel_9108\\2356757312.py:2: SAWarning: relationship 'Gene.foods' will copy column food.food_id to column food_gene.food_id, which conflicts with relationship(s): 'Food.genes' (copies food.food_id to food_gene.food_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"genes\"' to the 'Gene.foods' relationship. (Background on this warning at: https://sqlalche.me/e/20/qzyx) (This warning originated from the `configure_mappers()` process, which was invoked automatically in response to a user-initiated operation.)\n",
      "  print(\"Total Foods:\", db.session.query(Food.food_id).distinct().count())\n",
      "C:\\Users\\Sneha\\AppData\\Local\\Temp\\ipykernel_9108\\2356757312.py:2: SAWarning: relationship 'Food.food_disease' will copy column food.food_id to column food_disease.food_id, which conflicts with relationship(s): 'Disease.foods' (copies food.food_id to food_disease.food_id), 'Food.diseases' (copies food.food_id to food_disease.food_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"diseases,foods\"' to the 'Food.food_disease' relationship. (Background on this warning at: https://sqlalche.me/e/20/qzyx) (This warning originated from the `configure_mappers()` process, which was invoked automatically in response to a user-initiated operation.)\n",
      "  print(\"Total Foods:\", db.session.query(Food.food_id).distinct().count())\n",
      "C:\\Users\\Sneha\\AppData\\Local\\Temp\\ipykernel_9108\\2356757312.py:2: SAWarning: relationship 'Food_disease.food' will copy column food.food_id to column food_disease.food_id, which conflicts with relationship(s): 'Disease.foods' (copies food.food_id to food_disease.food_id), 'Food.diseases' (copies food.food_id to food_disease.food_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"diseases,foods\"' to the 'Food_disease.food' relationship. (Background on this warning at: https://sqlalche.me/e/20/qzyx) (This warning originated from the `configure_mappers()` process, which was invoked automatically in response to a user-initiated operation.)\n",
      "  print(\"Total Foods:\", db.session.query(Food.food_id).distinct().count())\n",
      "C:\\Users\\Sneha\\AppData\\Local\\Temp\\ipykernel_9108\\2356757312.py:2: SAWarning: relationship 'Disease.food_disease' will copy column disease.disease_id to column food_disease.disease_id, which conflicts with relationship(s): 'Disease.foods' (copies disease.disease_id to food_disease.disease_id), 'Food.diseases' (copies disease.disease_id to food_disease.disease_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"diseases,foods\"' to the 'Disease.food_disease' relationship. (Background on this warning at: https://sqlalche.me/e/20/qzyx) (This warning originated from the `configure_mappers()` process, which was invoked automatically in response to a user-initiated operation.)\n",
      "  print(\"Total Foods:\", db.session.query(Food.food_id).distinct().count())\n",
      "C:\\Users\\Sneha\\AppData\\Local\\Temp\\ipykernel_9108\\2356757312.py:2: SAWarning: relationship 'Food_disease.disease' will copy column disease.disease_id to column food_disease.disease_id, which conflicts with relationship(s): 'Disease.foods' (copies disease.disease_id to food_disease.disease_id), 'Food.diseases' (copies disease.disease_id to food_disease.disease_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"diseases,foods\"' to the 'Food_disease.disease' relationship. (Background on this warning at: https://sqlalche.me/e/20/qzyx) (This warning originated from the `configure_mappers()` process, which was invoked automatically in response to a user-initiated operation.)\n",
      "  print(\"Total Foods:\", db.session.query(Food.food_id).distinct().count())\n",
      "C:\\Users\\Sneha\\AppData\\Local\\Temp\\ipykernel_9108\\2356757312.py:2: SAWarning: relationship 'Disease.disease_gene' will copy column disease.disease_id to column disease_gene.disease_id, which conflicts with relationship(s): 'Disease.genes' (copies disease.disease_id to disease_gene.disease_id), 'Gene.diseases' (copies disease.disease_id to disease_gene.disease_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"diseases,genes\"' to the 'Disease.disease_gene' relationship. (Background on this warning at: https://sqlalche.me/e/20/qzyx) (This warning originated from the `configure_mappers()` process, which was invoked automatically in response to a user-initiated operation.)\n",
      "  print(\"Total Foods:\", db.session.query(Food.food_id).distinct().count())\n",
      "C:\\Users\\Sneha\\AppData\\Local\\Temp\\ipykernel_9108\\2356757312.py:2: SAWarning: relationship 'Disease_gene.disease' will copy column disease.disease_id to column disease_gene.disease_id, which conflicts with relationship(s): 'Disease.genes' (copies disease.disease_id to disease_gene.disease_id), 'Gene.diseases' (copies disease.disease_id to disease_gene.disease_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"diseases,genes\"' to the 'Disease_gene.disease' relationship. (Background on this warning at: https://sqlalche.me/e/20/qzyx) (This warning originated from the `configure_mappers()` process, which was invoked automatically in response to a user-initiated operation.)\n",
      "  print(\"Total Foods:\", db.session.query(Food.food_id).distinct().count())\n",
      "C:\\Users\\Sneha\\AppData\\Local\\Temp\\ipykernel_9108\\2356757312.py:2: SAWarning: relationship 'Gene.disease_gene' will copy column gene.gene_id to column disease_gene.gene_id, which conflicts with relationship(s): 'Disease.genes' (copies gene.gene_id to disease_gene.gene_id), 'Gene.diseases' (copies gene.gene_id to disease_gene.gene_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"diseases,genes\"' to the 'Gene.disease_gene' relationship. (Background on this warning at: https://sqlalche.me/e/20/qzyx) (This warning originated from the `configure_mappers()` process, which was invoked automatically in response to a user-initiated operation.)\n",
      "  print(\"Total Foods:\", db.session.query(Food.food_id).distinct().count())\n",
      "C:\\Users\\Sneha\\AppData\\Local\\Temp\\ipykernel_9108\\2356757312.py:2: SAWarning: relationship 'Disease_gene.gene' will copy column gene.gene_id to column disease_gene.gene_id, which conflicts with relationship(s): 'Disease.genes' (copies gene.gene_id to disease_gene.gene_id), 'Gene.diseases' (copies gene.gene_id to disease_gene.gene_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"diseases,genes\"' to the 'Disease_gene.gene' relationship. (Background on this warning at: https://sqlalche.me/e/20/qzyx) (This warning originated from the `configure_mappers()` process, which was invoked automatically in response to a user-initiated operation.)\n",
      "  print(\"Total Foods:\", db.session.query(Food.food_id).distinct().count())\n",
      "C:\\Users\\Sneha\\AppData\\Local\\Temp\\ipykernel_9108\\2356757312.py:2: SAWarning: relationship 'Food.food_gene' will copy column food.food_id to column food_gene.food_id, which conflicts with relationship(s): 'Food.genes' (copies food.food_id to food_gene.food_id), 'Gene.foods' (copies food.food_id to food_gene.food_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"foods,genes\"' to the 'Food.food_gene' relationship. (Background on this warning at: https://sqlalche.me/e/20/qzyx) (This warning originated from the `configure_mappers()` process, which was invoked automatically in response to a user-initiated operation.)\n",
      "  print(\"Total Foods:\", db.session.query(Food.food_id).distinct().count())\n",
      "C:\\Users\\Sneha\\AppData\\Local\\Temp\\ipykernel_9108\\2356757312.py:2: SAWarning: relationship 'Food_gene.food' will copy column food.food_id to column food_gene.food_id, which conflicts with relationship(s): 'Food.genes' (copies food.food_id to food_gene.food_id), 'Gene.foods' (copies food.food_id to food_gene.food_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"foods,genes\"' to the 'Food_gene.food' relationship. (Background on this warning at: https://sqlalche.me/e/20/qzyx) (This warning originated from the `configure_mappers()` process, which was invoked automatically in response to a user-initiated operation.)\n",
      "  print(\"Total Foods:\", db.session.query(Food.food_id).distinct().count())\n",
      "C:\\Users\\Sneha\\AppData\\Local\\Temp\\ipykernel_9108\\2356757312.py:2: SAWarning: relationship 'Gene.food_gene' will copy column gene.gene_id to column food_gene.gene_id, which conflicts with relationship(s): 'Food.genes' (copies gene.gene_id to food_gene.gene_id), 'Gene.foods' (copies gene.gene_id to food_gene.gene_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"foods,genes\"' to the 'Gene.food_gene' relationship. (Background on this warning at: https://sqlalche.me/e/20/qzyx) (This warning originated from the `configure_mappers()` process, which was invoked automatically in response to a user-initiated operation.)\n",
      "  print(\"Total Foods:\", db.session.query(Food.food_id).distinct().count())\n",
      "C:\\Users\\Sneha\\AppData\\Local\\Temp\\ipykernel_9108\\2356757312.py:2: SAWarning: relationship 'Food_gene.gene' will copy column gene.gene_id to column food_gene.gene_id, which conflicts with relationship(s): 'Food.genes' (copies gene.gene_id to food_gene.gene_id), 'Gene.foods' (copies gene.gene_id to food_gene.gene_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"foods,genes\"' to the 'Food_gene.gene' relationship. (Background on this warning at: https://sqlalche.me/e/20/qzyx) (This warning originated from the `configure_mappers()` process, which was invoked automatically in response to a user-initiated operation.)\n",
      "  print(\"Total Foods:\", db.session.query(Food.food_id).distinct().count())\n",
      "C:\\Users\\Sneha\\AppData\\Local\\Temp\\ipykernel_9108\\2356757312.py:2: SAWarning: relationship 'Chemical.chemical_disease' will copy column chemical.pubchem_id to column chemical_disease.pubchem_id, which conflicts with relationship(s): 'Chemical.diseases' (copies chemical.pubchem_id to chemical_disease.pubchem_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"diseases\"' to the 'Chemical.chemical_disease' relationship. (Background on this warning at: https://sqlalche.me/e/20/qzyx) (This warning originated from the `configure_mappers()` process, which was invoked automatically in response to a user-initiated operation.)\n",
      "  print(\"Total Foods:\", db.session.query(Food.food_id).distinct().count())\n",
      "C:\\Users\\Sneha\\AppData\\Local\\Temp\\ipykernel_9108\\2356757312.py:2: SAWarning: relationship 'Chemical_disease.chemical' will copy column chemical.pubchem_id to column chemical_disease.pubchem_id, which conflicts with relationship(s): 'Chemical.diseases' (copies chemical.pubchem_id to chemical_disease.pubchem_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"diseases\"' to the 'Chemical_disease.chemical' relationship. (Background on this warning at: https://sqlalche.me/e/20/qzyx) (This warning originated from the `configure_mappers()` process, which was invoked automatically in response to a user-initiated operation.)\n",
      "  print(\"Total Foods:\", db.session.query(Food.food_id).distinct().count())\n",
      "C:\\Users\\Sneha\\AppData\\Local\\Temp\\ipykernel_9108\\2356757312.py:2: SAWarning: relationship 'Disease.chemical_disease' will copy column disease.disease_id to column chemical_disease.disease_id, which conflicts with relationship(s): 'Chemical.diseases' (copies disease.disease_id to chemical_disease.disease_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"diseases\"' to the 'Disease.chemical_disease' relationship. (Background on this warning at: https://sqlalche.me/e/20/qzyx) (This warning originated from the `configure_mappers()` process, which was invoked automatically in response to a user-initiated operation.)\n",
      "  print(\"Total Foods:\", db.session.query(Food.food_id).distinct().count())\n",
      "C:\\Users\\Sneha\\AppData\\Local\\Temp\\ipykernel_9108\\2356757312.py:2: SAWarning: relationship 'Chemical_disease.disease' will copy column disease.disease_id to column chemical_disease.disease_id, which conflicts with relationship(s): 'Chemical.diseases' (copies disease.disease_id to chemical_disease.disease_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"diseases\"' to the 'Chemical_disease.disease' relationship. (Background on this warning at: https://sqlalche.me/e/20/qzyx) (This warning originated from the `configure_mappers()` process, which was invoked automatically in response to a user-initiated operation.)\n",
      "  print(\"Total Foods:\", db.session.query(Food.food_id).distinct().count())\n",
      "C:\\Users\\Sneha\\AppData\\Local\\Temp\\ipykernel_9108\\2356757312.py:2: SAWarning: relationship 'Food.food_chemical' will copy column food.food_id to column food_chemical.food_id, which conflicts with relationship(s): 'Chemical.foods' (copies food.food_id to food_chemical.food_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"foods\"' to the 'Food.food_chemical' relationship. (Background on this warning at: https://sqlalche.me/e/20/qzyx) (This warning originated from the `configure_mappers()` process, which was invoked automatically in response to a user-initiated operation.)\n",
      "  print(\"Total Foods:\", db.session.query(Food.food_id).distinct().count())\n",
      "C:\\Users\\Sneha\\AppData\\Local\\Temp\\ipykernel_9108\\2356757312.py:2: SAWarning: relationship 'Food_chemical.food' will copy column food.food_id to column food_chemical.food_id, which conflicts with relationship(s): 'Chemical.foods' (copies food.food_id to food_chemical.food_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"foods\"' to the 'Food_chemical.food' relationship. (Background on this warning at: https://sqlalche.me/e/20/qzyx) (This warning originated from the `configure_mappers()` process, which was invoked automatically in response to a user-initiated operation.)\n",
      "  print(\"Total Foods:\", db.session.query(Food.food_id).distinct().count())\n",
      "C:\\Users\\Sneha\\AppData\\Local\\Temp\\ipykernel_9108\\2356757312.py:2: SAWarning: relationship 'Chemical.food_chemical' will copy column chemical.pubchem_id to column food_chemical.pubchem_id, which conflicts with relationship(s): 'Chemical.foods' (copies chemical.pubchem_id to food_chemical.pubchem_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"foods\"' to the 'Chemical.food_chemical' relationship. (Background on this warning at: https://sqlalche.me/e/20/qzyx) (This warning originated from the `configure_mappers()` process, which was invoked automatically in response to a user-initiated operation.)\n",
      "  print(\"Total Foods:\", db.session.query(Food.food_id).distinct().count())\n",
      "C:\\Users\\Sneha\\AppData\\Local\\Temp\\ipykernel_9108\\2356757312.py:2: SAWarning: relationship 'Food_chemical.chemical' will copy column chemical.pubchem_id to column food_chemical.pubchem_id, which conflicts with relationship(s): 'Chemical.foods' (copies chemical.pubchem_id to food_chemical.pubchem_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"foods\"' to the 'Food_chemical.chemical' relationship. (Background on this warning at: https://sqlalche.me/e/20/qzyx) (This warning originated from the `configure_mappers()` process, which was invoked automatically in response to a user-initiated operation.)\n",
      "  print(\"Total Foods:\", db.session.query(Food.food_id).distinct().count())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Chemicals: 6992\n"
     ]
    }
   ],
   "source": [
    "with app.app_context():\n",
    "    print(\"Total Foods:\", db.session.query(Food.food_id).distinct().count())\n",
    "    print(\"Total Diseases:\", db.session.query(Disease.disease_id).distinct().count())\n",
    "    print(\"Total Genes:\", db.session.query(Gene.gene_id).distinct().count())\n",
    "    print(\"Total Chemicals:\", db.session.query(Chemical.pubchem_id).distinct().count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with app.app_context():\n",
    "    cats = [v[0] for v in (db.session.query(Food.food_category).distinct().all())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set([c for catlst in cats for c in catlst.split(', ')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Foods: 2337\n",
      "Total Foods: 2159\n",
      "Total Foods: 1491\n",
      "Total Diseases: 7610\n",
      "Total Genes: 20558\n",
      "Total Chemicals: 6992\n"
     ]
    }
   ],
   "source": [
    "with app.app_context():\n",
    "    print(\"Total Foods:\", len([val for val in db.session.query(Food_disease.food_id).distinct()]))\n",
    "    print(\"Total Foods:\", len([val for val in db.session.query(Food_gene.food_id).distinct()]))\n",
    "    print(\"Total Foods:\", len([val for val in db.session.query(Food_chemical.food_id).distinct()]))\n",
    "\n",
    "    print(\"Total Diseases:\", len([val for val in db.session.query(Disease.disease_id).distinct()]))\n",
    "    print(\"Total Genes:\", len([val for val in db.session.query(Gene.gene_id).distinct()]))\n",
    "    print(\"Total Chemicals:\", len([val for val in db.session.query(Chemical.pubchem_id).distinct()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique (food_id, disease_id) pairs: 280328\n"
     ]
    }
   ],
   "source": [
    "with app.app_context():\n",
    "    count = db.session.query(\n",
    "        func.count()\n",
    "    ).select_from(\n",
    "        db.session.query(Food_disease.food_id, Food_disease.disease_id).distinct().subquery()\n",
    "    ).scalar()\n",
    "\n",
    "    print(\"Unique (food_id, disease_id) pairs:\", count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique (food_id, pubchem_id) pairs: 66577\n"
     ]
    }
   ],
   "source": [
    "with app.app_context():\n",
    "    count = db.session.query(\n",
    "        func.count()\n",
    "    ).select_from(\n",
    "        db.session.query(Food_chemical.food_id, Food_chemical.pubchem_id).distinct().subquery()\n",
    "    ).scalar()\n",
    "\n",
    "    print(\"Unique (food_id, pubchem_id) pairs:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique (food_id, gene_id) pairs: 3792433\n"
     ]
    }
   ],
   "source": [
    "with app.app_context():\n",
    "    count = db.session.query(\n",
    "        func.count()\n",
    "    ).select_from(\n",
    "        db.session.query(Food_gene.food_id, Food_gene.gene_id).distinct().subquery()\n",
    "    ).scalar()\n",
    "\n",
    "    print(\"Unique (food_id, gene_id) pairs:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique (disease_id, gene_id) pairs: 5150217\n"
     ]
    }
   ],
   "source": [
    "with app.app_context():\n",
    "    count = db.session.query(\n",
    "        func.count()\n",
    "    ).select_from(\n",
    "        db.session.query(Disease_gene.disease_id, Disease_gene.gene_id).distinct().subquery()\n",
    "    ).scalar()\n",
    "\n",
    "    print(\"Unique (disease_id, gene_id) pairs:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique (pubchem_id, disease_id) pairs: 284612\n"
     ]
    }
   ],
   "source": [
    "with app.app_context():\n",
    "    count = db.session.query(\n",
    "        func.count()\n",
    "    ).select_from(\n",
    "        db.session.query(Chemical_disease.pubchem_id, Chemical_disease.disease_id).distinct().subquery()\n",
    "    ).scalar()\n",
    "\n",
    "    print(\"Unique (pubchem_id, disease_id) pairs:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique (pubchem_id, gene_id) pairs: 581465\n"
     ]
    }
   ],
   "source": [
    "with app.app_context():\n",
    "    count = db.session.query(\n",
    "        func.count()\n",
    "    ).select_from(\n",
    "        db.session.query(Chemical_gene.pubchem_id, Chemical_gene.gene_id).distinct().subquery()\n",
    "    ).scalar()\n",
    "\n",
    "    print(\"Unique (pubchem_id, gene_id) pairs:\", count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_colnames(df):\n",
    "    df.columns = [col.replace(' ', '-').lower() for col in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_primary_keys(model):\n",
    "    return [key.name for key in inspect(model).primary_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_db(obj, dl):\n",
    "    primary_keys = get_primary_keys(obj)\n",
    "\n",
    "    for i, item in enumerate(dl):\n",
    "        filter_kwargs = {key: item[key] for key in primary_keys if key in item}\n",
    "        existing = obj.query.filter_by(**filter_kwargs).first()\n",
    "\n",
    "        if existing:\n",
    "            continue  # Skip if already exists\n",
    "\n",
    "        db.session.add(obj(**item))\n",
    "        if (i + 1) % 5000 == 0:\n",
    "            db.session.commit()\n",
    "\n",
    "    db.session.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_db_df(obj, df):\n",
    "     primary_keys = get_primary_keys(obj)\n",
    "\n",
    "     for i, row in df.iterrows():\n",
    "         item = row.to_dict()\n",
    "         filter_kwargs = {key: item[key] for key in primary_keys if key in item}\n",
    "         existing = obj.query.filter_by(**filter_kwargs).first()\n",
    "\n",
    "         if existing:\n",
    "             continue  # Skip if already exists\n",
    "\n",
    "         db.session.add(obj(**item))\n",
    "         if (i + 1) % 5000 == 0:\n",
    "             db.session.commit()\n",
    "     db.session.commit()\n",
    "\n",
    "     \n",
    "#  import time\n",
    "# from sqlalchemy.exc import OperationalError\n",
    "\n",
    "# def add_to_db_df(obj, df, batch_size=500, max_retries=5, retry_wait=0.5):\n",
    "#     primary_keys = get_primary_keys(obj)\n",
    "\n",
    "#     for i, row in enumerate(df.iterrows()):\n",
    "#         item = row[1].to_dict()  # row is (index, Series)\n",
    "#         filter_kwargs = {key: item[key] for key in primary_keys if key in item}\n",
    "#         existing = obj.query.filter_by(**filter_kwargs).first()\n",
    "\n",
    "#         if existing:\n",
    "#             continue  # Skip if already exists\n",
    "\n",
    "#         db.session.add(obj(**item))\n",
    "\n",
    "#         # Commit in batches\n",
    "#         if (i + 1) % batch_size == 0:\n",
    "#             for attempt in range(max_retries):\n",
    "#                 try:\n",
    "#                     db.session.commit()\n",
    "#                     break\n",
    "#                 except OperationalError as e:\n",
    "#                     db.session.rollback()\n",
    "#                     print(f\"[Batch Commit Error] Attempt {attempt + 1} of {max_retries}: {e}\")\n",
    "#                     time.sleep(retry_wait * (attempt + 1))\n",
    "#             else:\n",
    "#                 print(f\"[Batch Commit Failed Permanently] Skipping batch ending at row {i + 1}\")\n",
    "\n",
    "#     # Final commit\n",
    "#     try:\n",
    "#         db.session.commit()\n",
    "#     except OperationalError as e:\n",
    "#         db.session.rollback()\n",
    "#         print(f\"[Final Commit Error] {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_from_db(obj):\n",
    "    obj.query.delete()\n",
    "    db.session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove_from_db(Food_disease)\n",
    "# remove_from_db(Food_chemical)\n",
    "# remove_from_db(Food_gene)\n",
    "# remove_from_db(Disease_gene)\n",
    "# remove_from_db(Chemical_disease)\n",
    "# remove_from_db(Chemical_gene)\n",
    "# remove_from_db(Food)\n",
    "# remove_from_db(Disease)\n",
    "# remove_from_db(Gene)\n",
    "# remove_from_db(References)\n",
    "# remove_from_db(Chemical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla Associations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Food-Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>food-id</th>\n",
       "      <th>disease-id</th>\n",
       "      <th>association</th>\n",
       "      <th>pmid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Plant ID:4045</td>\n",
       "      <td>MESH:D004487</td>\n",
       "      <td>negative</td>\n",
       "      <td>7398283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         food-id    disease-id association     pmid\n",
       "0  Plant ID:4045  MESH:D004487    negative  7398283"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_dis = pd.read_csv(DATA/'food-disease.tsv', sep='\\t', encoding='utf-8')\n",
    "food_dis.drop_duplicates(['food-id', 'disease-id', 'association', 'pmid'], inplace=True)\n",
    "food_dis = food_dis.where((pd.notnull(food_dis)), None)\n",
    "food_dis['association'] = food_dis['association'].apply(str.lower)\n",
    "food_dis = food_dis.loc[:, ['food-id', 'disease-id', 'association', 'pmid']]\n",
    "food_dis['pmid'] = food_dis['pmid'].apply(str)\n",
    "food2dis = defaultdict(lambda: set(),\n",
    "                       food_dis.groupby('food-id').agg(lambda s: set(s))['disease-id'].to_dict())\n",
    "food_dis.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_dis = food_dis[food_dis['food-id'].map(lambda s: 'Seafood' not in s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21207, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_dis.drop_duplicates(['food-id', 'disease-id', 'association']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1781"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(food_dis['food-id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Food-Chemical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>food-id</th>\n",
       "      <th>pubchem-id</th>\n",
       "      <th>content</th>\n",
       "      <th>reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Plant ID:100170</td>\n",
       "      <td>5280378</td>\n",
       "      <td>Detected but not quantified</td>\n",
       "      <td>KNApSAcK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           food-id  pubchem-id                      content reference\n",
       "0  Plant ID:100170     5280378  Detected but not quantified  KNApSAcK"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_chem = pd.read_csv(DATA/'food-chemical.tsv', sep='\\t', encoding='utf-8')\n",
    "food2chem = defaultdict(lambda: set(),\n",
    "                        food_chem.groupby('food-id').agg(lambda s: set(s))['pubchem-id'].to_dict())\n",
    "\n",
    "food_chem.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66577, 4)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_chem.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Gene-Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disease-id</th>\n",
       "      <th>gene-id</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MESH:C000591739</td>\n",
       "      <td>1588</td>\n",
       "      <td>ORPHANET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MESH:C000596385</td>\n",
       "      <td>26504</td>\n",
       "      <td>UNIPROT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MESH:C000598645</td>\n",
       "      <td>9499</td>\n",
       "      <td>CTD_human;ORPHANET;UNIPROT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MESH:C000600608</td>\n",
       "      <td>29940</td>\n",
       "      <td>ORPHANET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MESH:C000600608</td>\n",
       "      <td>113189</td>\n",
       "      <td>CTD_human;ORPHANET;UNIPROT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        disease-id  gene-id                      source\n",
       "0  MESH:C000591739     1588                    ORPHANET\n",
       "1  MESH:C000596385    26504                     UNIPROT\n",
       "2  MESH:C000598645     9499  CTD_human;ORPHANET;UNIPROT\n",
       "3  MESH:C000600608    29940                    ORPHANET\n",
       "4  MESH:C000600608   113189  CTD_human;ORPHANET;UNIPROT"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_dis = pd.read_csv(DATA/'gene-disease.tsv', sep='\\t', encoding='utf-8', index_col='Unnamed: 0')\n",
    "dis2gene = defaultdict(lambda: set(),\n",
    "                        gene_dis.groupby('disease-id').agg(lambda s: set(s))['gene-id'].to_dict())\n",
    "gene2dis = defaultdict(lambda: set(),\n",
    "                        gene_dis.groupby('gene-id').agg(lambda s: set(s))['disease-id'].to_dict())\n",
    "\n",
    "gene_dis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d. Chemical-Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pubchem-id</th>\n",
       "      <th>disease-id</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>MESH:D007674</td>\n",
       "      <td>therapeutic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pubchem-id    disease-id         type\n",
       "0          19  MESH:D007674  therapeutic"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chem_dis = pd.read_csv(DATA/'chemical-disease.tsv', sep='\\t', encoding='utf-8', index_col='Unnamed: 0')\n",
    "chem_dis = chem_dis.groupby(['pubchem-id', 'disease-id']).agg(lambda s: sorted(s)[-1]).reset_index()\n",
    "dis2chem = defaultdict(lambda: set(),\n",
    "                       chem_dis.groupby('disease-id').agg(lambda s: set(s))['pubchem-id'].to_dict())\n",
    "chem2dis = defaultdict(lambda: set(),\n",
    "                       chem_dis.groupby('pubchem-id').agg(lambda s: set(s))['disease-id'].to_dict())\n",
    "\n",
    "chem_dis.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e. Chemical-Gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pubchem-id</th>\n",
       "      <th>gene-id</th>\n",
       "      <th>interaction-actions</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>351</td>\n",
       "      <td>affects^binding|decreases^reaction</td>\n",
       "      <td>CTD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>4313</td>\n",
       "      <td>decreases^activity|decreases^reaction|decrease...</td>\n",
       "      <td>CTD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51</td>\n",
       "      <td>3091</td>\n",
       "      <td>affects^binding|affects^cotreatment|increases^...</td>\n",
       "      <td>CTD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51</td>\n",
       "      <td>7428</td>\n",
       "      <td>affects^binding|affects^cotreatment|increases^...</td>\n",
       "      <td>CTD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>8290</td>\n",
       "      <td>affects^cotreatment|decreases^methylation|incr...</td>\n",
       "      <td>CTD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pubchem-id  gene-id                                interaction-actions  \\\n",
       "0          19      351                 affects^binding|decreases^reaction   \n",
       "1          19     4313  decreases^activity|decreases^reaction|decrease...   \n",
       "2          51     3091  affects^binding|affects^cotreatment|increases^...   \n",
       "3          51     7428  affects^binding|affects^cotreatment|increases^...   \n",
       "4          51     8290  affects^cotreatment|decreases^methylation|incr...   \n",
       "\n",
       "  source  \n",
       "0    CTD  \n",
       "1    CTD  \n",
       "2    CTD  \n",
       "3    CTD  \n",
       "4    CTD  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chem_gene = pd.read_csv(DATA/'chemical-gene.tsv', sep='\\t', encoding='utf-8')\n",
    "chem2gene = defaultdict(lambda: set(),\n",
    "                        chem_gene.groupby('pubchem-id').agg(lambda s: set(s))['gene-id'].to_dict())\n",
    "gene2chem = defaultdict(lambda: set(),\n",
    "                        chem_gene.groupby('gene-id').agg(lambda s: set(s))['pubchem-id'].to_dict())\n",
    "chem_gene.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexicons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Food "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>common_names</th>\n",
       "      <th>food_id</th>\n",
       "      <th>food_category</th>\n",
       "      <th>display_name</th>\n",
       "      <th>scientific_name</th>\n",
       "      <th>tax_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alexanders; horse parsley</td>\n",
       "      <td>Plant ID:40962</td>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>Alexanders</td>\n",
       "      <td>Smyrnium olusatrum</td>\n",
       "      <td>40962.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>Plant ID:942083</td>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>Scrophularia umbrosa</td>\n",
       "      <td>Scrophularia umbrosa</td>\n",
       "      <td>942083.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dotted blazing star</td>\n",
       "      <td>Plant ID:344074</td>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>Dotted blazing star</td>\n",
       "      <td>Liatris punctata</td>\n",
       "      <td>344074.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>plymouth pear</td>\n",
       "      <td>Plant ID:761867</td>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>Plymouth pear</td>\n",
       "      <td>Pyrus cordata</td>\n",
       "      <td>761867.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>Plant ID:49166</td>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>Rhododendron kaempferi</td>\n",
       "      <td>Rhododendron kaempferi</td>\n",
       "      <td>49166.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                common_names          food_id  food_category  \\\n",
       "0  alexanders; horse parsley   Plant ID:40962  Miscellaneous   \n",
       "1                       None  Plant ID:942083  Miscellaneous   \n",
       "2        dotted blazing star  Plant ID:344074  Miscellaneous   \n",
       "3              plymouth pear  Plant ID:761867  Miscellaneous   \n",
       "4                       None   Plant ID:49166  Miscellaneous   \n",
       "\n",
       "             display_name         scientific_name    tax_id  \n",
       "0              Alexanders      Smyrnium olusatrum   40962.0  \n",
       "1    Scrophularia umbrosa    Scrophularia umbrosa  942083.0  \n",
       "2     Dotted blazing star        Liatris punctata  344074.0  \n",
       "3           Plymouth pear           Pyrus cordata  761867.0  \n",
       "4  Rhododendron kaempferi  Rhododendron kaempferi   49166.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read file\n",
    "foodlex = pd.read_csv(DATA/'food-lexicon-automated.tsv', sep='\\t', encoding='utf-8')\n",
    "clean_colnames(foodlex)\n",
    "\n",
    "del foodlex['foodb-group'], foodlex['foodb-subgroup']\n",
    "\n",
    "# Replace NaN with None\n",
    "foodlex = foodlex.where((pd.notnull(foodlex)), None)\n",
    "\n",
    "# Rename columns to match db schema.\n",
    "foodlex.rename(columns={\n",
    "    'common-names': 'common_names',\n",
    "    'food-name': 'display_name',\n",
    "    'food-id': 'food_id',\n",
    "    'food-category': 'food_category',\n",
    "    'scientific-name': 'scientific_name',\n",
    "    'tax-id':'tax_id',\n",
    "}, inplace=True)\n",
    "\n",
    "foodlex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redundancy check\n",
    "assert len((set(food_dis['food-id']) | set(food_chem['food-id'])) - set(foodlex['food_id'])) == 0,\\\n",
    "    'Food lexicon is not exhaustive!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump to disk\n",
    "foodlex.to_csv(DBDUMP/'food-lexicon.tsv', sep='\\t', encoding='utf-8', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with app.app_context():\n",
    "    data_list= list(foodlex.T.to_dict().values())\n",
    "    add_to_db(Food, data_list)\n",
    "    del data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disease_id</th>\n",
       "      <th>disease_name</th>\n",
       "      <th>disease_category</th>\n",
       "      <th>disease_synonyms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MESH:C538288</td>\n",
       "      <td>10p Deletion Syndrome (Partial)</td>\n",
       "      <td>Congenital abnormality|Genetic disease (inborn...</td>\n",
       "      <td>Chromosome 10, 10p- Partial|Chromosome 10, mon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MESH:C535484</td>\n",
       "      <td>13q deletion syndrome</td>\n",
       "      <td>Congenital abnormality|Genetic disease (inborn...</td>\n",
       "      <td>Chromosome 13q deletion|Chromosome 13q deletio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MESH:C579849</td>\n",
       "      <td>15q24 Microdeletion</td>\n",
       "      <td>Congenital abnormality|Genetic disease (inborn...</td>\n",
       "      <td>15q24 Deletion|15q24 Microdeletion Syndrome|In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MESH:C579850</td>\n",
       "      <td>16p11.2 Deletion Syndrome</td>\n",
       "      <td>Congenital abnormality|Genetic disease (inborn...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MESH:C567076</td>\n",
       "      <td>17,20-Lyase Deficiency, Isolated</td>\n",
       "      <td>Congenital abnormality|Endocrine system diseas...</td>\n",
       "      <td>17-Alpha-Hydroxylase-17,20-Lyase Deficiency, C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     disease_id                      disease_name  \\\n",
       "0  MESH:C538288   10p Deletion Syndrome (Partial)   \n",
       "1  MESH:C535484             13q deletion syndrome   \n",
       "2  MESH:C579849               15q24 Microdeletion   \n",
       "3  MESH:C579850         16p11.2 Deletion Syndrome   \n",
       "4  MESH:C567076  17,20-Lyase Deficiency, Isolated   \n",
       "\n",
       "                                    disease_category  \\\n",
       "0  Congenital abnormality|Genetic disease (inborn...   \n",
       "1  Congenital abnormality|Genetic disease (inborn...   \n",
       "2  Congenital abnormality|Genetic disease (inborn...   \n",
       "3  Congenital abnormality|Genetic disease (inborn...   \n",
       "4  Congenital abnormality|Endocrine system diseas...   \n",
       "\n",
       "                                    disease_synonyms  \n",
       "0  Chromosome 10, 10p- Partial|Chromosome 10, mon...  \n",
       "1  Chromosome 13q deletion|Chromosome 13q deletio...  \n",
       "2  15q24 Deletion|15q24 Microdeletion Syndrome|In...  \n",
       "3                                               None  \n",
       "4  17-Alpha-Hydroxylase-17,20-Lyase Deficiency, C...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dislex = pd.read_csv(DATA / 'CTD_diseases_new.tsv', sep='\\t', encoding='utf-8', on_bad_lines='skip')\n",
    "\n",
    "# Keep only selected columns.\n",
    "dislex = dislex[['DiseaseID', 'DiseaseName', 'SlimMappings', 'Synonyms']]\n",
    "\n",
    "# Replace nan with None\n",
    "dislex = dislex.where((pd.notnull(dislex)), None)\n",
    "\n",
    "# Rename to match schema\n",
    "dislex.rename(columns={\n",
    "    'DiseaseID': 'disease_id',\n",
    "    'DiseaseName': 'disease_name',\n",
    "    'SlimMappings': 'disease_category',\n",
    "    'Synonyms': 'disease_synonyms'\n",
    "}, inplace=True)\n",
    "\n",
    "dislex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redundancy check\n",
    "assert len((set(food_dis['disease-id']) | set(chem_dis['disease-id']) | set(gene_dis['disease-id'])) \n",
    "           - set(dislex['disease_id'])) == 0,\\\n",
    "    'Disease lexicon is not exhaustive!'\n",
    "\n",
    "# Subset disease lexicon\n",
    "dislex = dislex.set_index('disease_id').\\\n",
    "    loc[list(set(food_dis['disease-id']) | set(chem_dis['disease-id']) | set(gene_dis['disease-id']))].\\\n",
    "    reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dislex.to_csv(DBDUMP/'disease-lexicon.tsv', sep='\\t', encoding='utf-8', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with app.app_context():\n",
    "    add_to_db_df(Disease, dislex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Chemical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "chem = pd.read_csv(DATA/'chemical-lexicon.tsv', sep='\\t', encoding='utf-8').drop_duplicates(['pubchem_id'])\n",
    "\n",
    "# Replace nan with null values\n",
    "chem = chem.where((pd.notnull(chem)), None)\n",
    "\n",
    "# Rename columns\n",
    "chem.rename(columns={'canonical_smiles': 'smiles',},inplace=True)\n",
    "\n",
    "del chem['inchi'], chem['inchikey']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redundancy check\n",
    "assert len((set(food_chem['pubchem-id']) | set(chem_dis['pubchem-id']) | set(chem_gene['pubchem-id'])) \n",
    "           - set(chem['pubchem_id'])) == 0,\\\n",
    "    'Chemical lexicon is not exhaustive!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "chem.to_csv(DBDUMP/'chemical-lexicon.tsv', sep='\\t', encoding='utf-8', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "with app.app_context():\n",
    "    for i in range(0, len(chem), 50000):\n",
    "        data_list = list(chem.loc[i:50000-1+i, :].T.to_dict().values())\n",
    "        add_to_db(Chemical, data_list)\n",
    "        print(i)\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "# pip install biopython\n",
    "\n",
    "Entrez.email = \"rujhil24076@iiitd.ac.in\"\n",
    "\n",
    "def retrieve_annotation(id_list):\n",
    "\n",
    "    \"\"\"Annotates Entrez Gene IDs using Bio.Entrez, in particular epost (to\n",
    "    submit the data to NCBI) and esummary to retrieve the information.\n",
    "    Returns a list of dictionaries with the annotations.\"\"\"\n",
    "\n",
    "    request = Entrez.epost(\"gene\",id=\",\".join(id_list))\n",
    "    result = Entrez.read(request)\n",
    "\n",
    "    webEnv = result[\"WebEnv\"]\n",
    "    queryKey = result[\"QueryKey\"]\n",
    "    data = Entrez.esummary(db=\"gene\", webenv=webEnv, query_key =\n",
    "            queryKey)\n",
    "    annotations = Entrez.read(data)\n",
    "\n",
    "    return annotations\n",
    "\n",
    "records = list()\n",
    "covered = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covered: 100\n",
      "Covered: 1100\n",
      "Covered: 2100\n",
      "Covered: 3100\n",
      "Covered: 4100\n",
      "Covered: 5100\n",
      "Covered: 6100\n",
      "Covered: 7100\n",
      "Covered: 8100\n",
      "Covered: 9100\n",
      "Covered: 10100\n",
      "Covered: 11100\n",
      "Covered: 12100\n",
      "Covered: 13100\n",
      "Covered: 14100\n",
      "Covered: 15100\n",
      "Covered: 16100\n",
      "Covered: 17100\n",
      "Covered: 18100\n",
      "Covered: 19100\n",
      "Covered: 20100\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pickle\n",
    "from http.client import IncompleteRead\n",
    "\n",
    "with app.app_context():\n",
    "    genes = [str(g[0]) for g in db.session.query(Gene.gene_id).distinct().all()]\n",
    "\n",
    "for i in range(0, len(genes), 100):\n",
    "    if i in covered:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        batch = genes[i: i + 100]\n",
    "        annotation = retrieve_annotation(batch)\n",
    "        records += annotation['DocumentSummarySet']['DocumentSummary']\n",
    "        covered.append(i)\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            print(\"Covered:\", len(records))\n",
    "        \n",
    "        time.sleep(0.4)  # NCBI recommends max 3 requests per second\n",
    "\n",
    "    except IncompleteRead as e:\n",
    "        print(f\"IncompleteRead error at batch {i}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error at batch {i}: {e}\")\n",
    "        time.sleep(5)  # wait a bit longer before retrying next\n",
    "        continue\n",
    "\n",
    "# Final record processing\n",
    "records = [dict(d) for d in records]\n",
    "for rec, geneid in zip(records, genes):\n",
    "    rec['gene_id'] = geneid\n",
    "\n",
    "# Save results\n",
    "pickle.dump(records, open('data/version-3/gene-lexicon-raw.p', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_id</th>\n",
       "      <th>gene_name</th>\n",
       "      <th>gene_symbol</th>\n",
       "      <th>organism</th>\n",
       "      <th>other_symbols</th>\n",
       "      <th>synonyms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>alpha-1-B glycoprotein</td>\n",
       "      <td>A1BG</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>A1B, ABG, GAB, HYST2477</td>\n",
       "      <td>alpha-1B-glycoprotein|HEL-S-163pA|epididymis s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>N-acetyltransferase 2</td>\n",
       "      <td>NAT2</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>AAC2, NAT-2, PNAT</td>\n",
       "      <td>arylamine N-acetyltransferase 2|N-acetyltransf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gene_id               gene_name gene_symbol      organism  \\\n",
       "0       1  alpha-1-B glycoprotein        A1BG  Homo sapiens   \n",
       "1      10   N-acetyltransferase 2        NAT2  Homo sapiens   \n",
       "\n",
       "             other_symbols                                           synonyms  \n",
       "0  A1B, ABG, GAB, HYST2477  alpha-1B-glycoprotein|HEL-S-163pA|epididymis s...  \n",
       "1        AAC2, NAT-2, PNAT  arylamine N-acetyltransferase 2|N-acetyltransf...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = pickle.load(open('./data/version-3/gene-lexicon-raw.p', 'rb'))\n",
    "genelex = pd.DataFrame(records)\n",
    "\n",
    "# Subset\n",
    "genelex = genelex[['gene_id', 'Description', 'Name', 'Organism',\n",
    "                   'OtherAliases', 'OtherDesignations']]\n",
    "\n",
    "# Keep scientific name of organism only\n",
    "genelex['Organism'] = genelex['Organism'].map(lambda s: s['ScientificName'])\n",
    "\n",
    "# Rename columns\n",
    "genelex.rename(columns={\n",
    "    'Description': 'gene_name',\n",
    "    'Name': 'gene_symbol',\n",
    "    'Organism': 'organism',\n",
    "    'OtherAliases': 'other_symbols',\n",
    "    'OtherDesignations': 'synonyms'\n",
    "}, inplace=True)\n",
    "\n",
    "del records\n",
    "\n",
    "genelex.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotated gene IDs: 20558\n",
      "Total required gene IDs: 20550\n",
      "Missing gene IDs: 20550 (100.00%)\n",
      "Examples: [1, 2, 3, 131076, 9, 10, 12, 13, 14, 15]\n"
     ]
    }
   ],
   "source": [
    "# Count how many were annotated\n",
    "print(\"Annotated gene IDs:\", len(set(genelex['gene_id'])))\n",
    "\n",
    "# Count how many are in chemical-gene and gene-disease data\n",
    "all_needed = set(chem_gene['gene-id']) | set(gene_dis['gene-id'])\n",
    "print(\"Total required gene IDs:\", len(all_needed))\n",
    "\n",
    "# What fraction is missing?\n",
    "missing = all_needed - set(genelex['gene_id'])\n",
    "print(\"Missing gene IDs:\", len(missing), f\"({100 * len(missing)/len(all_needed):.2f}%)\")\n",
    "\n",
    "# Example missing gene IDs\n",
    "print(\"Examples:\", list(missing)[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If loaded from pickle\n",
    "import pickle\n",
    "genelex = pd.DataFrame(pickle.load(open('data/version-3/gene-lexicon-raw.p', 'rb')))\n",
    "\n",
    "# Ensure all gene IDs are strings (to match other DataFrames)\n",
    "genelex['gene_id'] = genelex['gene_id'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "chem_gene['gene-id'] = chem_gene['gene-id'].astype(str)\n",
    "gene_dis['gene-id'] = gene_dis['gene-id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Still missing: 0 gene IDs\n",
      "Example missing IDs: []\n"
     ]
    }
   ],
   "source": [
    "all_needed_genes = set(chem_gene['gene-id']) | set(gene_dis['gene-id'])\n",
    "available_genes = set(genelex['gene_id'])\n",
    "\n",
    "missing = all_needed_genes - available_genes\n",
    "\n",
    "print(f\" Still missing: {len(missing)} gene IDs\")\n",
    "print(f\"Example missing IDs: {list(missing)[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying 0 missing gene IDs...\n",
      " Final genelex now has 20558 entries.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from Bio import Entrez\n",
    "from http.client import IncompleteRead\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "Entrez.email = \"rujhil24076@iiitd.ac.in\"  # Update with your real email\n",
    "\n",
    "# Load current genelex and missing list\n",
    "genelex = pd.DataFrame(pickle.load(open('data/version-3/gene-lexicon-raw.p', 'rb')))\n",
    "genelex['gene_id'] = genelex['gene_id'].astype(str)\n",
    "\n",
    "all_needed_genes = set(chem_gene['gene-id'].astype(str)) | set(gene_dis['gene-id'].astype(str))\n",
    "existing_genes = set(genelex['gene_id'])\n",
    "still_missing = sorted(list(all_needed_genes - existing_genes))\n",
    "\n",
    "print(f\"Retrying {len(still_missing)} missing gene IDs...\")\n",
    "\n",
    "recovered = []\n",
    "\n",
    "for i in range(0, len(still_missing), 10):\n",
    "    batch = still_missing[i:i+10]\n",
    "\n",
    "    for attempt in range(3):  # up to 3 retries per batch\n",
    "        try:\n",
    "            annotation = retrieve_annotation(batch)\n",
    "            summaries = annotation['DocumentSummarySet']['DocumentSummary']\n",
    "\n",
    "            for rec, gid in zip(summaries, batch):\n",
    "                d = dict(rec)\n",
    "                d['gene_id'] = gid\n",
    "                recovered.append(d)\n",
    "\n",
    "            print(f\" Batch {i}-{i+10} recovered, total: {len(recovered)}\")\n",
    "            time.sleep(0.4)\n",
    "            break  # exit retry loop\n",
    "\n",
    "        except IncompleteRead:\n",
    "            print(f\" IncompleteRead at batch {i}-{i+10}, retrying...\")\n",
    "            time.sleep(2 * (attempt + 1))  # backoff\n",
    "        except Exception as e:\n",
    "            print(f\" Error at batch {i}-{i+10}: {e}\")\n",
    "            time.sleep(2 * (attempt + 1))\n",
    "\n",
    "# Merge with existing and save\n",
    "recovered_df = pd.DataFrame(recovered)\n",
    "genelex = pd.concat([genelex, recovered_df], ignore_index=True)\n",
    "genelex = genelex.drop_duplicates(subset=['gene_id'])\n",
    "\n",
    "pickle.dump(genelex.to_dict(orient='records'), open('data/version-3/gene-lexicon-full.p', 'wb'))\n",
    "\n",
    "print(f\" Final genelex now has {len(genelex)} entries.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "genelex.to_csv(DBDUMP/'gene-lexicon.tsv', sep='\\t', encoding='utf-8', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Name', 'Description', 'Status', 'CurrentID', 'Chromosome',\n",
      "       'GeneticSource', 'MapLocation', 'OtherAliases', 'OtherDesignations',\n",
      "       'NomenclatureSymbol', 'NomenclatureName', 'NomenclatureStatus', 'Mim',\n",
      "       'GenomicInfo', 'GeneWeight', 'Summary', 'ChrSort', 'ChrStart',\n",
      "       'Organism', 'LocationHist', 'gene_id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(genelex.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "genelex_renamed = genelex.rename(columns={\n",
    "    'Name': 'gene_name',\n",
    "    'NomenclatureSymbol': 'gene_symbol',\n",
    "    'Organism': 'organism',\n",
    "    'OtherAliases': 'other_symbols',\n",
    "    'OtherDesignations': 'synonyms'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_cols = ['gene_id', 'gene_name', 'gene_symbol', 'organism', 'other_symbols', 'synonyms']\n",
    "\n",
    "# Only keep the columns that are now present\n",
    "available_cols = [col for col in valid_cols if col in genelex_renamed.columns]\n",
    "\n",
    "cleaned_genelex = genelex_renamed[available_cols].copy()\n",
    "\n",
    "# Fill missing columns with None\n",
    "for col in valid_cols:\n",
    "    if col not in cleaned_genelex.columns:\n",
    "        cleaned_genelex[col] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_genelex['organism'] = cleaned_genelex['organism'].apply(\n",
    "    lambda org: org.get('ScientificName') if isinstance(org, dict) else org\n",
    ")\n",
    "\n",
    "with app.app_context():\n",
    "    add_to_db_df(Gene, cleaned_genelex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>authors</th>\n",
       "      <th>date</th>\n",
       "      <th>journal_name</th>\n",
       "      <th>journal_name_abbr</th>\n",
       "      <th>publication_type</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17344941</td>\n",
       "      <td>Elkiran T|Harputluoglu H|Yasar U|Babaoglu MO|D...</td>\n",
       "      <td>2007 Jan-Feb</td>\n",
       "      <td>Methods and findings in experimental and clini...</td>\n",
       "      <td>Methods Find Exp Clin Pharmacol</td>\n",
       "      <td>Clinical Trial|Journal Article</td>\n",
       "      <td>Differential alteration of drug-metabolizing e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25456153</td>\n",
       "      <td>Severins N|Mensink RP|Plat J</td>\n",
       "      <td>2015 Feb</td>\n",
       "      <td>Nutrition, metabolism, and cardiovascular dise...</td>\n",
       "      <td>Nutr Metab Cardiovasc Dis</td>\n",
       "      <td>Journal Article|Randomized Controlled Trial</td>\n",
       "      <td>Effects of lutein-enriched egg yolk in butterm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23922960</td>\n",
       "      <td>Li C|Zuo C|Deng G|Kuang R|Yang Q|Hu C|Sheng O|...</td>\n",
       "      <td>2013</td>\n",
       "      <td>PloS one</td>\n",
       "      <td>PLoS One</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>Contamination of bananas with beauvericin and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8766742</td>\n",
       "      <td>Gneser S|Atici A|Cengizler I|Alparslan N</td>\n",
       "      <td>1996 May-Jun</td>\n",
       "      <td>Allergologia et immunopathologia</td>\n",
       "      <td>Allergol Immunopathol (Madr)</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>Inhalant allergens: as a cause of respiratory ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19918387</td>\n",
       "      <td>Brvar M|Bunc M</td>\n",
       "      <td>2009 Sep 9</td>\n",
       "      <td>Cases journal</td>\n",
       "      <td>Cases J</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>High-degree atrioventricular block in acute et...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pmid                                            authors          date  \\\n",
       "0  17344941  Elkiran T|Harputluoglu H|Yasar U|Babaoglu MO|D...  2007 Jan-Feb   \n",
       "1  25456153                       Severins N|Mensink RP|Plat J      2015 Feb   \n",
       "2  23922960  Li C|Zuo C|Deng G|Kuang R|Yang Q|Hu C|Sheng O|...          2013   \n",
       "3   8766742          Gneser S|Atici A|Cengizler I|Alparslan N  1996 May-Jun   \n",
       "4  19918387                                     Brvar M|Bunc M    2009 Sep 9   \n",
       "\n",
       "                                        journal_name  \\\n",
       "0  Methods and findings in experimental and clini...   \n",
       "1  Nutrition, metabolism, and cardiovascular dise...   \n",
       "2                                           PloS one   \n",
       "3                   Allergologia et immunopathologia   \n",
       "4                                      Cases journal   \n",
       "\n",
       "                 journal_name_abbr  \\\n",
       "0  Methods Find Exp Clin Pharmacol   \n",
       "1        Nutr Metab Cardiovasc Dis   \n",
       "2                         PLoS One   \n",
       "3     Allergol Immunopathol (Madr)   \n",
       "4                          Cases J   \n",
       "\n",
       "                              publication_type  \\\n",
       "0               Clinical Trial|Journal Article   \n",
       "1  Journal Article|Randomized Controlled Trial   \n",
       "2                              Journal Article   \n",
       "3                              Journal Article   \n",
       "4                              Journal Article   \n",
       "\n",
       "                                               title  \n",
       "0  Differential alteration of drug-metabolizing e...  \n",
       "1  Effects of lutein-enriched egg yolk in butterm...  \n",
       "2  Contamination of bananas with beauvericin and ...  \n",
       "3  Inhalant allergens: as a cause of respiratory ...  \n",
       "4  High-degree atrioventricular block in acute et...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "references = pd.read_csv(DATA/'publication-records.tsv', sep='\\t', encoding='utf-8')\n",
    "clean_colnames(references)\n",
    "\n",
    "references = references.where((pd.notnull(references)), None)\n",
    "\n",
    "references.rename(columns={\n",
    "    'authors': 'authors',\n",
    "    'journal-name': 'journal_name',\n",
    "    'journal-name-abbrv.': 'journal_name_abbr',\n",
    "    'publication-type':'publication_type',\n",
    "},inplace=True)\n",
    "\n",
    "pmids_not_mapped = list(str(s) for s in set(food_dis['pmid'].apply(int)) - set(references['pmid']))\n",
    "references = references.set_index('pmid').\\\n",
    "    reindex(index=references.pmid.tolist() + pmids_not_mapped).fillna('').\\\n",
    "    reset_index()\n",
    "\n",
    "references.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "references.to_csv(DBDUMP/'references.tsv', sep='\\t', encoding='utf-8', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with app.app_context():\n",
    "    add_to_db_df(References, references)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Associations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Food-Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>food-id</th>\n",
       "      <th>disease-id</th>\n",
       "      <th>pubchem-id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Plant ID:100170</td>\n",
       "      <td>MESH:D002583</td>\n",
       "      <td>5280378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plant ID:100170</td>\n",
       "      <td>MESH:D058186</td>\n",
       "      <td>5280378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           food-id    disease-id pubchem-id\n",
       "0  Plant ID:100170  MESH:D002583    5280378\n",
       "1  Plant ID:100170  MESH:D058186    5280378"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Curated\n",
    "neg_fd = food_dis[food_dis.association == 'negative'].\\\n",
    "    groupby(['food-id', 'disease-id']).agg(lambda s: '|'.join(s))[['pmid']].reset_index(())\n",
    "neg_fd.reset_index(inplace=True)\n",
    "neg_fd.rename(columns={'pmid': 'negative-pmid'}, inplace=True)\n",
    "\n",
    "pos_fd = food_dis[food_dis.association == 'positive'].\\\n",
    "    groupby(['food-id', 'disease-id']).agg(lambda s: '|'.join(s))[['pmid']]\n",
    "pos_fd.reset_index(inplace=True)\n",
    "pos_fd.rename(columns={'pmid': 'positive-pmid'}, inplace=True)\n",
    "\n",
    "food_dis_curated = pos_fd.merge(neg_fd, on=['food-id', 'disease-id'], how='outer').fillna('')\n",
    "\n",
    "# Inferred\n",
    "fd_inferred = list()\n",
    "for food, chemicals in food2chem.items():\n",
    "    for chem in chemicals:\n",
    "        for dis in chem2dis[chem]:\n",
    "            fd_inferred.append([food, dis, str(chem)])\n",
    "            \n",
    "fd_inferred = pd.DataFrame(fd_inferred, \n",
    "                           columns=['food-id', 'disease-id', 'pubchem-id'])\n",
    "fd_inferred = fd_inferred.groupby(['food-id', 'disease-id']).agg(lambda s: '|'.join(s)).reset_index()\n",
    "del pos_fd, neg_fd\n",
    "\n",
    "fd_inferred.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>food_id</th>\n",
       "      <th>disease_id</th>\n",
       "      <th>positive_pmid</th>\n",
       "      <th>negative_pmid</th>\n",
       "      <th>pubchem_id</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AlcoholicBev ID:17</td>\n",
       "      <td>MESH:D001523</td>\n",
       "      <td>7195588</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AlcoholicBev ID:17</td>\n",
       "      <td>MESH:D003866</td>\n",
       "      <td>6798614</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AlcoholicBev ID:17</td>\n",
       "      <td>MESH:D004487</td>\n",
       "      <td></td>\n",
       "      <td>27873566</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AlcoholicBev ID:17</td>\n",
       "      <td>MESH:D011041</td>\n",
       "      <td></td>\n",
       "      <td>11639831</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AlcoholicBev ID:18</td>\n",
       "      <td>MESH:D001249</td>\n",
       "      <td></td>\n",
       "      <td>6639863</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              food_id    disease_id positive_pmid negative_pmid pubchem_id  \\\n",
       "0  AlcoholicBev ID:17  MESH:D001523       7195588                            \n",
       "1  AlcoholicBev ID:17  MESH:D003866       6798614                            \n",
       "2  AlcoholicBev ID:17  MESH:D004487                    27873566              \n",
       "3  AlcoholicBev ID:17  MESH:D011041                    11639831              \n",
       "4  AlcoholicBev ID:18  MESH:D001249                     6639863              \n",
       "\n",
       "   weight  \n",
       "0       2  \n",
       "1       2  \n",
       "2       2  \n",
       "3       2  \n",
       "4       2  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_dis_db = food_dis_curated.merge(fd_inferred, on=['food-id', 'disease-id'], how='outer').fillna('')\n",
    "food_dis_db['weight'] = food_dis_db.apply(lambda row: len(row['positive-pmid'].split('|')) +\n",
    "                                          len(row['negative-pmid'].split('|')), 1)\n",
    "del fd_inferred, food_dis_curated\n",
    "\n",
    "food_dis_db = food_dis_db.where((pd.notnull(food_dis_db)), None)\n",
    "\n",
    "food_dis_db.rename(columns={\n",
    "    'food-id': 'food_id',\n",
    "    'disease-id': 'disease_id',\n",
    "    'positive-pmid': 'positive_pmid',\n",
    "    'negative-pmid': 'negative_pmid',\n",
    "    'pubchem-id': 'pubchem_id',\n",
    "    'weight':'weight',\n",
    "}, inplace=True)\n",
    "\n",
    "food_dis_db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_dis_db.to_csv(DBDUMP/'food-disease.tsv', sep='\\t', encoding='utf-8', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with app.app_context():\n",
    "    add_to_db_df(Food_disease, food_dis_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Food-chemical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>food_id</th>\n",
       "      <th>pubchem_id</th>\n",
       "      <th>content</th>\n",
       "      <th>references</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Plant ID:100170</td>\n",
       "      <td>5280378</td>\n",
       "      <td>Detected but not quantified</td>\n",
       "      <td>KNApSAcK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plant ID:100170</td>\n",
       "      <td>44260113</td>\n",
       "      <td>Detected but not quantified</td>\n",
       "      <td>KNApSAcK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Plant ID:100506</td>\n",
       "      <td>1150</td>\n",
       "      <td>Detected but not quantified</td>\n",
       "      <td>KNApSAcK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Plant ID:100506</td>\n",
       "      <td>5202</td>\n",
       "      <td>Detected but not quantified</td>\n",
       "      <td>KNApSAcK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Plant ID:100506</td>\n",
       "      <td>5372945</td>\n",
       "      <td>Detected but not quantified</td>\n",
       "      <td>KNApSAcK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           food_id  pubchem_id                      content references\n",
       "0  Plant ID:100170     5280378  Detected but not quantified   KNApSAcK\n",
       "1  Plant ID:100170    44260113  Detected but not quantified   KNApSAcK\n",
       "2  Plant ID:100506        1150  Detected but not quantified   KNApSAcK\n",
       "3  Plant ID:100506        5202  Detected but not quantified   KNApSAcK\n",
       "4  Plant ID:100506     5372945  Detected but not quantified   KNApSAcK"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_chem_db = food_chem.where((pd.notnull(food_chem)), None)\n",
    "\n",
    "food_chem_db = food_chem_db.where((pd.notnull(food_chem_db)), None)\n",
    "\n",
    "food_chem_db.rename(columns={\n",
    "    'pubchem-id': 'pubchem_id',\n",
    "    'food-id': 'food_id',\n",
    "    'reference': 'references',\n",
    "    'type':'type_relation',\n",
    "    'inference-network':'inference_network'\n",
    "}, inplace=True)\n",
    "\n",
    "food_chem_db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_chem_db.to_csv(DBDUMP/'food-chemical.tsv', sep='\\t', encoding='utf-8', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "with app.app_context():\n",
    "    add_to_db_df(Food_chemical, food_chem_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Food-gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Chemical inference aggregation ---\n",
    "fg_inf_chem = []\n",
    "for food, chemlst in food2chem.items():\n",
    "    for chem in chemlst:\n",
    "        for gene in chem2gene[chem]:\n",
    "            fg_inf_chem.append((food, gene, chem))\n",
    "\n",
    "df_chem = pd.DataFrame(fg_inf_chem, columns=['food_id', 'gene_id', 'pubchem_id'])\n",
    "df_chem['gene_id'] = df_chem['gene_id'].astype(str)\n",
    "df_chem['food_id'] = df_chem['food_id'].astype(str)\n",
    "\n",
    "# Convert pubchem_id to str during aggregation\n",
    "df_chem = df_chem.groupby(['food_id', 'gene_id'])['pubchem_id'].apply(\n",
    "    lambda x: '|'.join(sorted(set(str(i) for i in x)))\n",
    ").reset_index()\n",
    "df_chem.rename(columns={'pubchem_id': 'via_chemicals'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Disease inference aggregation ---\n",
    "fg_inf_dis = []\n",
    "for food, dislst in food2dis.items():\n",
    "    for dis in dislst:\n",
    "        for gene in dis2gene[dis]:\n",
    "            fg_inf_dis.append((food, gene, dis))\n",
    "\n",
    "df_dis = pd.DataFrame(fg_inf_dis, columns=['food_id', 'gene_id', 'disease_id'])\n",
    "df_dis['gene_id'] = df_dis['gene_id'].astype(str)\n",
    "df_dis['food_id'] = df_dis['food_id'].astype(str)\n",
    "\n",
    "df_dis = df_dis.groupby(['food_id', 'gene_id'])['disease_id'].apply(\n",
    "    lambda x: '|'.join(sorted(set(x)))\n",
    ").reset_index()\n",
    "df_dis.rename(columns={'disease_id': 'via_diseases'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'food-id': {0: 'AlcoholicBev ID:17',\n",
       "  1: 'AlcoholicBev ID:17',\n",
       "  2: 'AlcoholicBev ID:17',\n",
       "  3: 'AlcoholicBev ID:17',\n",
       "  4: 'AlcoholicBev ID:17'},\n",
       " 'gene-id': {0: 2, 1: 15, 2: 52, 3: 81, 4: 100},\n",
       " 'disease-id': {0: 'MESH:D003866',\n",
       "  1: 'MESH:D003866',\n",
       "  2: 'MESH:D003866',\n",
       "  3: 'MESH:D004487',\n",
       "  4: 'MESH:D004487'}}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fg_inf_chem.head()\n",
    "fg_inf_dis.head().to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure everything is string\n",
    "df_dis['gene_id'] = df_dis['gene_id'].astype(str)\n",
    "df_dis['food_id'] = df_dis['food_id'].astype(str)\n",
    "df_chem['gene_id'] = df_chem['gene_id'].astype(str)\n",
    "df_chem['food_id'] = df_chem['food_id'].astype(str)\n",
    "\n",
    "# Merge with full outer join on common keys\n",
    "food_gene_db = pd.merge(df_dis, df_chem, on=['food_id', 'gene_id'], how='outer')\n",
    "\n",
    "# Fill NaN with empty string for merge consistency\n",
    "food_gene_db['via_diseases'] = food_gene_db['via_diseases'].fillna('')\n",
    "food_gene_db['via_chemicals'] = food_gene_db['via_chemicals'].fillna('')\n",
    "\n",
    "# Deduplicate and rejoin in case of multiple entries per key\n",
    "food_gene_db = food_gene_db.groupby(['food_id', 'gene_id']).agg({\n",
    "    'via_diseases': lambda x: '|'.join(sorted(set(i for i in x if i))),\n",
    "    'via_chemicals': lambda x: '|'.join(sorted(set(i for i in x if i)))\n",
    "}).reset_index()\n",
    "\n",
    "# Final weight column (correct parentheses)\n",
    "food_gene_db['weight'] = food_gene_db.apply(\n",
    "    lambda row:\n",
    "        (len(row['via_diseases'].split('|')) if row['via_diseases'] else 0) +\n",
    "        (len(row['via_chemicals'].split('|')) if row['via_chemicals'] else 0),\n",
    "    axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_gene_db['weight'] = food_gene_db.apply(\n",
    "    lambda row: \n",
    "        (len(str(row['via_diseases']).split('|')) if row['via_diseases'] else 0) +\n",
    "        (len(str(row['via_chemicals']).split('|')) if row['via_chemicals'] else 0),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_gene_db.to_csv(DBDUMP/'food-gene.tsv', sep='\\t', encoding='utf-8', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_db_df_fg(obj, df):\n",
    "    df = df.where(pd.notnull(df), None)\n",
    "\n",
    "    # Get model's valid columns\n",
    "    model_columns = {c.name for c in obj.__table__.columns}\n",
    "    df = df[[col for col in df.columns if col in model_columns]]  # Drop extras like 'weight'\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        item = row.to_dict()\n",
    "        db.session.merge(obj(**item))\n",
    "\n",
    "        if (i + 1) % 5000 == 0:\n",
    "            db.session.commit()\n",
    "\n",
    "    db.session.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "with app.app_context():\n",
    "# del food_gene_db['weight']\n",
    "    add_to_db_df_fg(Food_gene, food_gene_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disease Gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disease-id</th>\n",
       "      <th>gene-id</th>\n",
       "      <th>pubchem-id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MESH:C531617</td>\n",
       "      <td>14</td>\n",
       "      <td>14985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MESH:C531617</td>\n",
       "      <td>35</td>\n",
       "      <td>14985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     disease-id  gene-id pubchem-id\n",
       "0  MESH:C531617       14      14985\n",
       "1  MESH:C531617       35      14985"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Curated\n",
    "dg_curated = gene_dis.copy(deep=True)\n",
    "\n",
    "# Inferred through chemicals\n",
    "dg_inferred = list()\n",
    "for disease, chemlst in dis2chem.items():\n",
    "    for chem in chemlst:\n",
    "        for gene in chem2gene[chem]:\n",
    "            dg_inferred.append([disease, str(chem), gene])\n",
    "            \n",
    "dg_inferred = pd.DataFrame(dg_inferred, columns=['disease-id', 'pubchem-id', 'gene-id'])\n",
    "dg_inferred = dg_inferred.groupby(['disease-id', 'gene-id']).agg(lambda s: '|'.join(s)).reset_index()\n",
    "dg_inferred.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg_curated['gene-id'] = dg_curated['gene-id'].astype(str)\n",
    "dg_inferred['gene-id'] = dg_inferred['gene-id'].astype(str)\n",
    "dg_curated['disease-id'] = dg_curated['disease-id'].astype(str)\n",
    "dg_inferred['disease-id'] = dg_inferred['disease-id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_gene_db = dg_curated.merge(dg_inferred, on=['disease-id', 'gene-id'], how='outer').fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_gene_db.rename(columns={'pubchem-id': 'via-chemicals'}, inplace=True)\n",
    "del dg_inferred, dg_curated\n",
    "\n",
    "disease_gene_db = disease_gene_db.where((pd.notnull(disease_gene_db)), None)\n",
    "\n",
    "disease_gene_db.rename(columns={\n",
    "    'gene-id': 'gene_id',\n",
    "    'disease-id': 'disease_id',\n",
    "    'via-chemicals': 'via_chemicals',\n",
    "    'source': 'reference'\n",
    "}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_gene_db.to_csv(DBDUMP/'disease-gene.tsv', sep='\\t', encoding='utf-8', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with app.app_context():\n",
    "    add_to_db_df(Disease_gene, disease_gene_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disease chemical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disease-id</th>\n",
       "      <th>pubchem-id</th>\n",
       "      <th>gene-id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MESH:C000591739</td>\n",
       "      <td>10680</td>\n",
       "      <td>1588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MESH:C000591739</td>\n",
       "      <td>14403</td>\n",
       "      <td>1588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        disease-id pubchem-id gene-id\n",
       "0  MESH:C000591739      10680    1588\n",
       "1  MESH:C000591739      14403    1588"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Curated\n",
    "chem_dis_curated = chem_dis.copy(deep=True)\n",
    "chem_dis_curated['pubchem-id'] = chem_dis_curated['pubchem-id'].apply(str)\n",
    "\n",
    "# Inferred through genes\n",
    "dc_inferred = list()\n",
    "for disease, genelst in dis2gene.items():\n",
    "    for gene in genelst:\n",
    "        for chem in gene2chem[gene]:\n",
    "            dc_inferred.append([disease, str(chem), str(gene)])\n",
    "            \n",
    "dc_inferred = pd.DataFrame(dc_inferred, columns=['disease-id', 'pubchem-id', 'gene-id'])\n",
    "dc_inferred = dc_inferred.groupby(['disease-id', 'pubchem-id']).agg(lambda s: '|'.join(s)).reset_index()\n",
    "dc_inferred.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disease-id</th>\n",
       "      <th>pubchem-id</th>\n",
       "      <th>via-genes</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MESH:C000591739</td>\n",
       "      <td>10680</td>\n",
       "      <td>1588</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        disease-id pubchem-id via-genes type\n",
       "0  MESH:C000591739      10680      1588     "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge\n",
    "disease_chem_db = dc_inferred.merge(chem_dis_curated, on=['disease-id', 'pubchem-id'], how='outer').fillna('')\n",
    "disease_chem_db.rename(columns={'gene-id': 'via-genes'}, inplace=True)\n",
    "# del disease_chem_db['type']\n",
    "del dc_inferred, chem_dis_curated\n",
    "\n",
    "disease_chem_db.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disease_chem_db['weight'] = disease_chem_db['via-genes'].apply(lambda s: len(s.split('|')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_chem_db = disease_chem_db.where((pd.notnull(disease_chem_db)), None)\n",
    "\n",
    "disease_chem_db.rename(columns={\n",
    "    'pubchem-id': 'pubchem_id',\n",
    "    'disease-id': 'disease_id',\n",
    "    'type':'type_relation',\n",
    "    'via-genes':'via_genes'\n",
    "},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_chem_db.to_csv(DBDUMP/'disease-chemical.tsv', sep='\\t', encoding='utf-8', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with app.app_context():\n",
    "    add_to_db_df(Chemical_disease, disease_chem_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gene Chemical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curated\n",
    "chem_gene_curated = chem_gene.copy(deep=True)\n",
    "chem_gene_curated['gene-id'] = chem_gene_curated['gene-id'].apply(str)\n",
    "chem_gene_curated['pubchem-id'] = chem_gene_curated['pubchem-id'].apply(str)\n",
    "\n",
    "# Inferred through diseases\n",
    "gc_inferred = list()\n",
    "for gene, dislst in gene2dis.items():\n",
    "    for dis in dislst:\n",
    "        for chem in dis2chem[dis]:\n",
    "            gc_inferred.append([str(gene), str(chem), dis])\n",
    "            \n",
    "gc_inferred = pd.DataFrame(gc_inferred, columns=['gene-id', 'pubchem-id', 'disease-id'])\n",
    "gc_inferred = gc_inferred.groupby(['gene-id', 'pubchem-id']).agg(lambda s: '|'.join(s)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "chem_gene_db = gc_inferred.merge(chem_gene_curated, on=['gene-id', 'pubchem-id'], how='outer').fillna('')\n",
    "chem_gene_db.rename(columns={'disease-id': 'via-diseases'}, inplace=True)\n",
    "del chem_gene_db['source']\n",
    "del gc_inferred, chem_gene_curated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chem_gene_db = chem_gene_db.where((pd.notnull(chem_gene_db)), None)\n",
    "\n",
    "chem_gene_db.rename(columns={\n",
    "    'pubchem-id': 'pubchem_id',\n",
    "    'gene-id': 'gene_id',\n",
    "    'via-diseases': 'via_diseases',\n",
    "    'interaction-actions': 'interaction_actions'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chem_gene_db = pd.read_csv(DATA / 'chemical-gene.tsv', sep='\\t', encoding='utf-8', index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with app.app_context():\n",
    "    add_to_db_df(Chemical_gene, chem_gene_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chemical Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import MolFromSmiles, Draw\n",
    "from rdkit.Chem.AllChem import Compute2DCoords\n",
    "from shutil import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!rm /dietrx/static/images/molecules/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16:01:53] unsupported number of radical electrons 4\n",
      "[16:01:59] unsupported number of radical electrons 4\n",
      "[16:02:22] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:02:22] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:02:22] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:02:22] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:02:22] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:02:22] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:02:22] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:02:22] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:02:23] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:02:23] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:02:23] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:02:23] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:02:23] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:02:23] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:02:23] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:02:23] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:02:23] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:02:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:02:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:02:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:02:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:02:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:02:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:02:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:02:31] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:02:35] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:02:35] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:02:36] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:02:36] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:02:38] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:02:38] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:02:38] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:02:38] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "with app.app_context():\n",
    "    for mol in Chemical.query.all():\n",
    "        try:\n",
    "            m = MolFromSmiles(mol.smiles)\n",
    "            tmp = Compute2DCoords(m)\n",
    "            Draw.MolToFile(m, 'static/images/molecules/' + str(mol.pubchem_id) + '.png')\n",
    "        except:\n",
    "            print(mol.mol_id, mol.smiles)\n",
    "            copy('static/images/no-image.png', \n",
    "                'static/images/molecules/' + str(mol.pubchem_id) + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SDF Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "covered = set(list(int(p.name[:-4]) for p in Path('static/sdf_files/').glob('*.sdf')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: 0\n",
      "Completed: 10\n",
      "Completed: 20\n",
      "Completed: 30\n",
      "Completed: 40\n",
      "Completed: 50\n",
      "Completed: 60\n",
      "Completed: 70\n",
      "Completed: 80\n",
      "Completed: 90\n",
      "Completed: 100\n",
      "Completed: 110\n",
      "Completed: 120\n",
      "Completed: 130\n",
      "Completed: 140\n",
      "Completed: 150\n",
      "Completed: 160\n",
      "Completed: 170\n",
      "Completed: 180\n",
      "Completed: 190\n",
      "Completed: 200\n",
      "Completed: 210\n",
      "Completed: 220\n",
      "Completed: 230\n",
      "Completed: 240\n",
      "Completed: 250\n",
      "Completed: 260\n",
      "Completed: 270\n",
      "Completed: 280\n",
      "Completed: 290\n",
      "Completed: 300\n",
      "Completed: 310\n",
      "Completed: 320\n",
      "Completed: 330\n",
      "Completed: 340\n",
      "Completed: 350\n",
      "Completed: 360\n",
      "Completed: 370\n",
      "Completed: 380\n",
      "Completed: 390\n",
      "Completed: 400\n",
      "Completed: 410\n",
      "Completed: 420\n",
      "Completed: 430\n",
      "Completed: 440\n",
      "Completed: 450\n",
      "Completed: 460\n",
      "Completed: 470\n",
      "Completed: 480\n",
      "Completed: 490\n",
      "Completed: 500\n",
      "Completed: 510\n",
      "Completed: 520\n",
      "Completed: 530\n",
      "Completed: 540\n",
      "Completed: 550\n",
      "Completed: 560\n",
      "Completed: 570\n",
      "Completed: 580\n",
      "Completed: 590\n",
      "Completed: 600\n",
      "Completed: 610\n",
      "Completed: 620\n",
      "Completed: 630\n",
      "Completed: 640\n",
      "Completed: 650\n",
      "Completed: 660\n",
      "Completed: 670\n",
      "Completed: 680\n",
      "Completed: 690\n",
      "Completed: 700\n",
      "Completed: 710\n",
      "Completed: 720\n",
      "Completed: 730\n",
      "Completed: 740\n",
      "Completed: 750\n",
      "Completed: 760\n",
      "Completed: 770\n",
      "Completed: 780\n",
      "Completed: 790\n",
      "Completed: 800\n",
      "Completed: 810\n",
      "Completed: 820\n",
      "Completed: 830\n",
      "Completed: 840\n",
      "Completed: 850\n",
      "Completed: 860\n",
      "Completed: 870\n",
      "Completed: 880\n",
      "Completed: 890\n",
      "Completed: 900\n",
      "Completed: 910\n",
      "Completed: 920\n",
      "Completed: 930\n",
      "Completed: 940\n",
      "Completed: 950\n",
      "Completed: 960\n",
      "Completed: 970\n",
      "Completed: 980\n",
      "Completed: 990\n",
      "Completed: 1000\n",
      "Completed: 1010\n",
      "Completed: 1020\n",
      "Completed: 1030\n",
      "Completed: 1040\n",
      "Completed: 1050\n",
      "Completed: 1060\n",
      "Completed: 1070\n",
      "Completed: 1080\n",
      "Completed: 1090\n",
      "Completed: 1100\n",
      "Completed: 1110\n",
      "Completed: 1120\n",
      "Completed: 1130\n",
      "Completed: 1140\n",
      "Completed: 1150\n",
      "Completed: 1160\n",
      "Completed: 1170\n",
      "Completed: 1180\n",
      "Completed: 1190\n",
      "Completed: 1200\n",
      "Completed: 1210\n",
      "Completed: 1220\n",
      "Completed: 1230\n",
      "Completed: 1240\n",
      "Completed: 1250\n",
      "Completed: 1260\n",
      "Completed: 1270\n",
      "Completed: 1280\n",
      "Completed: 1290\n",
      "Completed: 1300\n",
      "Completed: 1310\n",
      "Completed: 1320\n",
      "Completed: 1330\n",
      "Completed: 1340\n",
      "Completed: 1350\n",
      "Completed: 1360\n",
      "Completed: 1370\n",
      "Completed: 1380\n",
      "Completed: 1390\n",
      "Completed: 1400\n",
      "Completed: 1410\n",
      "Completed: 1420\n",
      "Completed: 1430\n",
      "Completed: 1440\n",
      "Completed: 1450\n",
      "Completed: 1460\n",
      "Completed: 1470\n",
      "Completed: 1480\n",
      "Completed: 1490\n",
      "Completed: 1500\n",
      "Completed: 1510\n",
      "Completed: 1520\n",
      "Completed: 1530\n",
      "Completed: 1540\n",
      "Completed: 1550\n",
      "Completed: 1560\n",
      "Completed: 1570\n",
      "Completed: 1580\n",
      "Completed: 1590\n",
      "Completed: 1600\n",
      "Completed: 1610\n",
      "Completed: 1620\n",
      "Completed: 1630\n",
      "Completed: 1640\n",
      "Completed: 1650\n",
      "Completed: 1660\n",
      "Completed: 1670\n",
      "Completed: 1680\n",
      "Completed: 1690\n",
      "Completed: 1700\n",
      "Completed: 1710\n",
      "Completed: 1720\n",
      "Completed: 1730\n",
      "Completed: 1740\n",
      "Completed: 1750\n",
      "Completed: 1760\n",
      "Completed: 1770\n",
      "Completed: 1780\n",
      "Completed: 1790\n",
      "Completed: 1800\n",
      "Completed: 1810\n",
      "Completed: 1820\n",
      "Completed: 1830\n",
      "Completed: 1840\n",
      "Completed: 1850\n",
      "Completed: 1860\n",
      "Completed: 1870\n",
      "Completed: 1880\n",
      "Completed: 1890\n",
      "Completed: 1900\n",
      "Completed: 1910\n",
      "Completed: 1920\n",
      "Completed: 1930\n",
      "Completed: 1940\n",
      "Completed: 1950\n",
      "Completed: 1960\n",
      "Completed: 1970\n",
      "Completed: 1980\n",
      "Completed: 1990\n",
      "Completed: 2000\n",
      "Completed: 2010\n",
      "Completed: 2020\n",
      "Completed: 2030\n",
      "Completed: 2040\n",
      "Completed: 2050\n",
      "Completed: 2060\n",
      "Completed: 2070\n",
      "Completed: 2080\n",
      "Completed: 2090\n",
      "Completed: 2100\n",
      "Completed: 2110\n",
      "Completed: 2120\n",
      "Completed: 2130\n",
      "Completed: 2140\n",
      "Completed: 2150\n",
      "Completed: 2160\n",
      "Completed: 2170\n",
      "Completed: 2180\n",
      "Completed: 2190\n",
      "Completed: 2200\n",
      "Completed: 2210\n",
      "Completed: 2220\n",
      "Completed: 2230\n",
      "Completed: 2240\n",
      "Completed: 2250\n",
      "Completed: 2260\n",
      "Completed: 2270\n",
      "Completed: 2280\n",
      "Completed: 2290\n",
      "Completed: 2300\n",
      "Completed: 2310\n",
      "Completed: 2320\n",
      "Completed: 2330\n",
      "Completed: 2340\n",
      "Completed: 2350\n",
      "Completed: 2360\n",
      "Completed: 2370\n",
      "Completed: 2380\n",
      "Completed: 2390\n",
      "Completed: 2400\n",
      "Completed: 2410\n",
      "Completed: 2420\n",
      "Completed: 2430\n",
      "Completed: 2440\n",
      "Completed: 2450\n",
      "Completed: 2460\n",
      "Completed: 2470\n",
      "Completed: 2480\n",
      "Completed: 2490\n",
      "Completed: 2500\n",
      "Completed: 2510\n",
      "Completed: 2520\n",
      "Completed: 2530\n",
      "Completed: 2540\n",
      "Completed: 2550\n",
      "Completed: 2560\n",
      "Completed: 2570\n",
      "Completed: 2580\n",
      "Completed: 2590\n",
      "Completed: 2600\n",
      "Completed: 2610\n",
      "Completed: 2620\n",
      "Completed: 2630\n",
      "Completed: 2640\n",
      "Completed: 2650\n",
      "Completed: 2660\n",
      "Completed: 2670\n",
      "Completed: 2680\n",
      "Completed: 2690\n",
      "Completed: 2700\n",
      "Completed: 2710\n",
      "Completed: 2720\n",
      "Completed: 2730\n",
      "Completed: 2740\n",
      "Completed: 2750\n",
      "Completed: 2760\n",
      "Completed: 2770\n",
      "Completed: 2780\n",
      "Completed: 2790\n",
      "Completed: 2800\n",
      "Completed: 2810\n",
      "Completed: 2820\n",
      "Completed: 2830\n",
      "Completed: 2840\n",
      "Completed: 2850\n",
      "Completed: 2860\n",
      "Completed: 2870\n",
      "Completed: 2880\n",
      "Completed: 2890\n",
      "Completed: 2900\n",
      "Completed: 2910\n",
      "Completed: 2920\n",
      "Completed: 2930\n",
      "Completed: 2940\n",
      "Completed: 2950\n",
      "Completed: 2960\n",
      "Completed: 2970\n",
      "Completed: 2980\n",
      "Completed: 2990\n",
      "Completed: 3000\n",
      "Completed: 3010\n",
      "Completed: 3020\n",
      "Completed: 3030\n",
      "Completed: 3040\n",
      "Completed: 3050\n",
      "Completed: 3060\n",
      "Completed: 3070\n",
      "Completed: 3080\n",
      "Completed: 3090\n",
      "Completed: 3100\n",
      "Completed: 3110\n",
      "Completed: 3120\n",
      "Completed: 3130\n",
      "Completed: 3140\n",
      "Completed: 3150\n",
      "Completed: 3160\n",
      "Completed: 3170\n",
      "Completed: 3180\n",
      "Completed: 3190\n",
      "Completed: 3200\n",
      "Completed: 3210\n",
      "Completed: 3220\n",
      "Completed: 3230\n",
      "Completed: 3240\n",
      "Completed: 3250\n",
      "Completed: 3260\n",
      "Completed: 3270\n",
      "Completed: 3280\n",
      "Completed: 3290\n",
      "Completed: 3300\n",
      "Completed: 3310\n",
      "Completed: 3320\n",
      "Completed: 3330\n",
      "Completed: 3340\n",
      "Completed: 3350\n",
      "Completed: 3360\n",
      "Completed: 3370\n",
      "Completed: 3380\n",
      "Completed: 3390\n",
      "Completed: 3400\n",
      "Completed: 3410\n",
      "Completed: 3420\n",
      "Completed: 3430\n",
      "Completed: 3440\n",
      "Completed: 3450\n",
      "Completed: 3460\n",
      "Completed: 3470\n",
      "Completed: 3480\n",
      "Completed: 3490\n",
      "Completed: 3500\n",
      "Completed: 3510\n",
      "Completed: 3520\n",
      "Completed: 3530\n",
      "Completed: 3540\n",
      "Completed: 3550\n",
      "Completed: 3560\n",
      "Completed: 3570\n",
      "Completed: 3580\n",
      "Completed: 3590\n",
      "Completed: 3600\n",
      "Completed: 3610\n",
      "Completed: 3620\n",
      "Completed: 3630\n",
      "Completed: 3640\n",
      "Completed: 3650\n",
      "Completed: 3660\n",
      "Completed: 3670\n",
      "Completed: 3680\n",
      "Completed: 3690\n",
      "Completed: 3700\n",
      "Completed: 3710\n",
      "Completed: 3720\n",
      "Completed: 3730\n",
      "Completed: 3740\n",
      "Completed: 3750\n",
      "Completed: 3760\n",
      "Completed: 3770\n",
      "Completed: 3780\n",
      "Completed: 3790\n",
      "Completed: 3800\n",
      "Completed: 3810\n",
      "Completed: 3820\n",
      "Completed: 3830\n",
      "Completed: 3840\n",
      "Completed: 3850\n",
      "Completed: 3860\n",
      "Completed: 3870\n",
      "Completed: 3880\n",
      "Completed: 3890\n",
      "Completed: 3900\n",
      "Completed: 3910\n",
      "Completed: 3920\n",
      "Completed: 3930\n",
      "Completed: 3940\n",
      "Completed: 3950\n",
      "Completed: 3960\n",
      "Completed: 3970\n",
      "Completed: 3980\n",
      "Completed: 3990\n",
      "Completed: 4000\n",
      "Completed: 4010\n",
      "Completed: 4020\n",
      "Completed: 4030\n",
      "Completed: 4040\n",
      "Completed: 4050\n",
      "Completed: 4060\n",
      "Completed: 4070\n",
      "Completed: 4080\n",
      "Completed: 4090\n",
      "Completed: 4100\n",
      "Completed: 4110\n",
      "Completed: 4120\n",
      "Completed: 4130\n",
      "Completed: 4140\n",
      "Completed: 4150\n",
      "Completed: 4160\n",
      "Completed: 4170\n",
      "Completed: 4180\n",
      "Completed: 4190\n",
      "Completed: 4200\n",
      "Completed: 4210\n",
      "Completed: 4220\n",
      "Completed: 4230\n",
      "Completed: 4240\n",
      "Completed: 4250\n",
      "Completed: 4260\n",
      "Completed: 4270\n",
      "Completed: 4280\n",
      "Completed: 4290\n",
      "Completed: 4300\n",
      "Completed: 4310\n",
      "Completed: 4320\n",
      "Completed: 4330\n",
      "Completed: 4340\n",
      "Completed: 4350\n",
      "Completed: 4360\n",
      "Completed: 4370\n",
      "Completed: 4380\n",
      "Completed: 4390\n",
      "Completed: 4400\n",
      "Completed: 4410\n",
      "Completed: 4420\n",
      "Completed: 4430\n",
      "Completed: 4440\n",
      "Completed: 4450\n",
      "Completed: 4460\n",
      "Completed: 4470\n",
      "Completed: 4480\n",
      "Completed: 4490\n",
      "Completed: 4500\n",
      "Completed: 4510\n",
      "Completed: 4520\n",
      "Completed: 4530\n",
      "Completed: 4540\n",
      "Completed: 4550\n",
      "Completed: 4560\n",
      "Completed: 4570\n",
      "Completed: 4580\n",
      "Completed: 4590\n",
      "Completed: 4600\n",
      "Completed: 4610\n",
      "Completed: 4620\n",
      "Completed: 4630\n",
      "Completed: 4640\n",
      "Completed: 4650\n",
      "Completed: 4660\n",
      "Completed: 4670\n",
      "Completed: 4680\n",
      "Completed: 4690\n",
      "Completed: 4700\n",
      "Completed: 4710\n",
      "Completed: 4720\n",
      "Completed: 4730\n",
      "Completed: 4740\n",
      "Completed: 4750\n",
      "Completed: 4760\n",
      "Completed: 4770\n",
      "Completed: 4780\n",
      "Completed: 4790\n",
      "Completed: 4800\n",
      "Completed: 4810\n",
      "Completed: 4820\n",
      "Completed: 4830\n",
      "Completed: 4840\n",
      "Completed: 4850\n",
      "Completed: 4860\n",
      "Completed: 4870\n",
      "Completed: 4880\n",
      "Completed: 4890\n",
      "Completed: 4900\n",
      "Completed: 4910\n",
      "Completed: 4920\n",
      "Completed: 4930\n",
      "Completed: 4940\n",
      "Completed: 4950\n",
      "Completed: 4960\n",
      "Completed: 4970\n",
      "Completed: 4980\n",
      "Completed: 4990\n",
      "Completed: 5000\n",
      "Completed: 5010\n",
      "Completed: 5020\n",
      "Completed: 5030\n",
      "Completed: 5040\n",
      "Completed: 5050\n",
      "Completed: 5060\n",
      "Completed: 5070\n",
      "Completed: 5080\n",
      "Completed: 5090\n",
      "Completed: 5100\n",
      "Completed: 5110\n",
      "Completed: 5120\n",
      "Completed: 5130\n",
      "Completed: 5140\n",
      "Completed: 5150\n",
      "Completed: 5160\n",
      "Completed: 5170\n",
      "Completed: 5180\n",
      "Completed: 5190\n",
      "Completed: 5200\n",
      "Completed: 5210\n",
      "Completed: 5220\n",
      "Completed: 5230\n",
      "Completed: 5240\n",
      "Completed: 5250\n",
      "Completed: 5260\n",
      "Completed: 5270\n",
      "Completed: 5280\n",
      "Completed: 5290\n",
      "Completed: 5300\n",
      "Completed: 5310\n",
      "Completed: 5320\n",
      "Completed: 5330\n",
      "Completed: 5340\n",
      "Completed: 5350\n",
      "Completed: 5360\n",
      "Completed: 5370\n",
      "Completed: 5380\n",
      "Completed: 5390\n",
      "Completed: 5400\n",
      "Completed: 5410\n",
      "Completed: 5420\n",
      "Completed: 5430\n",
      "Completed: 5440\n",
      "Completed: 5450\n",
      "Completed: 5460\n",
      "Completed: 5470\n",
      "Completed: 5480\n",
      "Completed: 5490\n",
      "Completed: 5500\n",
      "Completed: 5510\n",
      "Completed: 5520\n",
      "Completed: 5530\n",
      "Completed: 5540\n",
      "Completed: 5550\n",
      "Completed: 5560\n",
      "Completed: 5570\n",
      "Completed: 5580\n",
      "Completed: 5590\n",
      "Completed: 5600\n",
      "Completed: 5610\n",
      "Completed: 5620\n",
      "Completed: 5630\n",
      "Completed: 5640\n",
      "Completed: 5650\n",
      "Completed: 5660\n",
      "Completed: 5670\n",
      "Completed: 5680\n",
      "Completed: 5690\n",
      "Completed: 5700\n",
      "Completed: 5710\n",
      "Completed: 5720\n",
      "Completed: 5730\n",
      "Completed: 5740\n",
      "Completed: 5750\n",
      "Completed: 5760\n",
      "Completed: 5770\n",
      "Completed: 5780\n",
      "Completed: 5790\n",
      "Completed: 5800\n",
      "Completed: 5810\n",
      "Completed: 5820\n",
      "Completed: 5830\n",
      "Completed: 5840\n",
      "Completed: 5850\n",
      "Completed: 5860\n",
      "Completed: 5870\n",
      "Completed: 5880\n",
      "Completed: 5890\n",
      "Completed: 5900\n",
      "Completed: 5910\n",
      "Completed: 5920\n",
      "Completed: 5930\n",
      "Completed: 5940\n",
      "Completed: 5950\n",
      "Completed: 5960\n",
      "Completed: 5970\n",
      "Completed: 5980\n",
      "Completed: 5990\n",
      "Completed: 6000\n",
      "Completed: 6010\n",
      "Completed: 6020\n",
      "Completed: 6030\n",
      "Completed: 6040\n",
      "Completed: 6050\n",
      "Completed: 6060\n",
      "Completed: 6070\n",
      "Completed: 6080\n",
      "Completed: 6090\n",
      "Completed: 6100\n",
      "Completed: 6110\n",
      "Completed: 6120\n",
      "Completed: 6130\n",
      "Completed: 6140\n",
      "Completed: 6150\n",
      "Completed: 6160\n",
      "Completed: 6170\n",
      "Completed: 6180\n",
      "Completed: 6190\n",
      "Completed: 6200\n",
      "Completed: 6210\n",
      "Completed: 6220\n",
      "Completed: 6230\n",
      "Completed: 6240\n",
      "Completed: 6250\n",
      "Completed: 6260\n",
      "Completed: 6270\n",
      "Completed: 6280\n",
      "Completed: 6290\n",
      "Completed: 6300\n",
      "Completed: 6310\n",
      "Completed: 6320\n",
      "Completed: 6330\n",
      "Completed: 6340\n",
      "Completed: 6350\n",
      "Completed: 6360\n",
      "Completed: 6370\n",
      "Completed: 6380\n",
      "Completed: 6390\n",
      "Completed: 6400\n",
      "Completed: 6410\n",
      "Completed: 6420\n",
      "Completed: 6430\n",
      "Completed: 6440\n",
      "Completed: 6450\n",
      "Completed: 6460\n",
      "Completed: 6470\n",
      "Completed: 6480\n",
      "Completed: 6490\n",
      "Completed: 6500\n",
      "Completed: 6510\n",
      "Completed: 6520\n",
      "Completed: 6530\n",
      "Completed: 6540\n",
      "Completed: 6550\n",
      "Completed: 6560\n",
      "Completed: 6570\n",
      "Completed: 6580\n",
      "Completed: 6590\n",
      "Completed: 6600\n",
      "Completed: 6610\n",
      "Completed: 6620\n",
      "Completed: 6630\n",
      "Completed: 6640\n",
      "Completed: 6650\n",
      "Completed: 6660\n",
      "Completed: 6670\n",
      "Completed: 6680\n",
      "Completed: 6690\n",
      "Completed: 6700\n",
      "Completed: 6710\n",
      "Completed: 6720\n",
      "Completed: 6730\n",
      "Completed: 6740\n",
      "Completed: 6750\n",
      "Completed: 6760\n",
      "Completed: 6770\n",
      "Completed: 6780\n",
      "Completed: 6790\n",
      "Completed: 6800\n",
      "Completed: 6810\n",
      "Completed: 6820\n",
      "Completed: 6830\n",
      "Completed: 6840\n",
      "Completed: 6850\n",
      "Completed: 6860\n",
      "Completed: 6870\n",
      "Completed: 6880\n",
      "Completed: 6890\n",
      "Completed: 6900\n",
      "Completed: 6910\n",
      "Completed: 6920\n",
      "Completed: 6930\n",
      "Completed: 6940\n",
      "Completed: 6950\n",
      "Completed: 6960\n",
      "Completed: 6970\n",
      "Completed: 6980\n",
      "Completed: 6990\n"
     ]
    }
   ],
   "source": [
    "with app.app_context():\n",
    "    for i, mol in enumerate(Chemical.query.all()):\n",
    "        if mol.pubchem_id not in covered:\n",
    "            r = requests.get('https://cactus.nci.nih.gov/chemical/structure/%s/file?format=sdf&get3d=True' % mol.smiles)\n",
    "            with open('static/sdf_files/%i.sdf' % mol.pubchem_id, 'w') as f:\n",
    "                f.write(r.text)\n",
    "                covered.add(i)\n",
    "            \n",
    "        if i % 10 == 0:\n",
    "            print(\"Completed: %i\" %i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refrest Elastic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sneha\\AppData\\Local\\Temp\\ipykernel_9108\\3898774582.py:1: DeprecationWarning: Passing transport options in the API method is deprecated. Use 'Elasticsearch.options()' instead.\n",
      "  app.elasticsearch.indices.delete(index='food', ignore=[400, 404])\n",
      "C:\\Users\\Sneha\\AppData\\Local\\Temp\\ipykernel_9108\\3898774582.py:1: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.17/security-minimal-setup.html to enable security.\n",
      "  app.elasticsearch.indices.delete(index='food', ignore=[400, 404])\n",
      "C:\\Users\\Sneha\\AppData\\Local\\Temp\\ipykernel_9108\\3898774582.py:2: DeprecationWarning: Passing transport options in the API method is deprecated. Use 'Elasticsearch.options()' instead.\n",
      "  app.elasticsearch.indices.delete(index='disease', ignore=[400, 404])\n",
      "C:\\Users\\Sneha\\AppData\\Local\\Temp\\ipykernel_9108\\3898774582.py:2: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.17/security-minimal-setup.html to enable security.\n",
      "  app.elasticsearch.indices.delete(index='disease', ignore=[400, 404])\n",
      "C:\\Users\\Sneha\\AppData\\Local\\Temp\\ipykernel_9108\\3898774582.py:3: DeprecationWarning: Passing transport options in the API method is deprecated. Use 'Elasticsearch.options()' instead.\n",
      "  app.elasticsearch.indices.delete(index='gene', ignore=[400, 404])\n",
      "C:\\Users\\Sneha\\AppData\\Local\\Temp\\ipykernel_9108\\3898774582.py:3: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.17/security-minimal-setup.html to enable security.\n",
      "  app.elasticsearch.indices.delete(index='gene', ignore=[400, 404])\n",
      "C:\\Users\\Sneha\\Documents\\DietRX_New\\search.py:9: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.17/security-minimal-setup.html to enable security.\n",
      "  app.elasticsearch.index(index=index, id=getattr(model, id), body=payload)\n",
      "C:\\Users\\Sneha\\AppData\\Local\\Temp\\ipykernel_9108\\3898774582.py:10: DeprecationWarning: Passing transport options in the API method is deprecated. Use 'Elasticsearch.options()' instead.\n",
      "  app.elasticsearch.indices.delete(index='chemical', ignore=[400, 404])\n",
      "C:\\Users\\Sneha\\AppData\\Local\\Temp\\ipykernel_9108\\3898774582.py:10: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.17/security-minimal-setup.html to enable security.\n",
      "  app.elasticsearch.indices.delete(index='chemical', ignore=[400, 404])\n"
     ]
    }
   ],
   "source": [
    "app.elasticsearch.indices.delete(index='food', ignore=[400, 404])\n",
    "app.elasticsearch.indices.delete(index='disease', ignore=[400, 404])\n",
    "app.elasticsearch.indices.delete(index='gene', ignore=[400, 404])\n",
    "\n",
    "with app.app_context():\n",
    "    Food.reindex(\"food_id\")\n",
    "    Disease.reindex(\"disease_id\")\n",
    "    Gene.reindex(\"gene_id\")\n",
    "\n",
    "    app.elasticsearch.indices.delete(index='chemical', ignore=[400, 404])\n",
    "\n",
    "    Chemical.reindex(\"pubchem_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with app.app_context():\n",
    "    query = db.session.query(Food_disease.food_id.distinct().label(\"food_id\"))\n",
    "    food_ids = [row.food_id for row in query.all()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with app.app_context():\n",
    "    query = db.session.query(Food_chemical.food_id.distinct().label(\"food_id\"))\n",
    "    food_ids += [row.food_id for row in query.all()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with app.app_context():\n",
    "    query = db.session.query(Food_gene.food_id.distinct().label(\"food_id\"))\n",
    "    food_ids += [row.food_id for row in query.all()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_ids = set(food_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with app.app_context():\n",
    "    query = db.session.query(Food.food_id.distinct().label(\"food_id\"))\n",
    "    all_food_ids = set([row.food_id for row in query.all()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_ids = all_food_ids - food_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with app.app_context():\n",
    "    for fid in empty_ids:\n",
    "        Food.query.filter_by(food_id=fid).delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with app.app_context():\n",
    "    db.session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with app.app_context():\n",
    "    for obj in Food.query.filter(Food.food_id.in_(list(all_food_ids - food_ids))).all():\n",
    "        db.session.delete(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Food Cherax tenuimanus>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with app.app_context():\n",
    "    valid_food_ids = {f.food_id for f in db.session.query(Food.food_id).distinct()}\n",
    "    all_food_ids = {fc.food_id for fc in db.session.query(Food_chemical.food_id).distinct()}\n",
    "    renegade_ids = list(all_food_ids - valid_food_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with app.app_context():\n",
    "    for obj in Food_chemical.query.filter(Food_chemical.food_id.in_(renegade_ids)).all():\n",
    "        db.session.delete(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with app.app_context():\n",
    "    db.session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with app.app_context():\n",
    "    results = db.session.query(Food_disease).join(Food).filter(Food.food_category == 'Seafood').all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with app.app_context():\n",
    "    Food.query.filter_by(food_category='Seafood').delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with app.app_context():\n",
    "    db.session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
